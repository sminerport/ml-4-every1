{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c01d4e",
   "metadata": {},
   "source": [
    "# Evaluating Regressors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9ee2b37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from mlwpy import *\n",
    "%matplotlib inline\n",
    "\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "tts = skms.train_test_split(diabetes.data,\n",
    "                            diabetes.target,\n",
    "                            test_size=.25,\n",
    "                            random_state=42)\n",
    "\n",
    "(diabetes_train_ftrs, diabetes_test_ftrs,\n",
    " diabetes_train_tgt,  diabetes_test_tgt) = tts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee97be2",
   "metadata": {},
   "source": [
    "# 7.1 BaselineRegressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2494db",
   "metadata": {},
   "source": [
    "Regressors, like classifiers need simple baseline strategies to compete against.  In `sklearn`s back of tricks, we can easily create baseline models that predict the mean and the median, which are fixed values for a given training dataset.  Once we train on the dataset, the baseline returns a single value which serves as our prediction for all examples.  Another approach is to pick arbirary constants out of ahat.  For example, if a rare disease causes fever and most people are healthy, a temperature near 98.6 degrees Fahrenheit could be a good baseline temperature prediction.\n",
    "\n",
    "The `quantile` generalizes the idea of the `median`.  The median is a specific percentile--the 50th percentile.  The 75th percentile has 75% of the data less than it and 25% of the data greater.\n",
    "\n",
    "Using `quantile`, we can pick an arbitrary percent as our break point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6189da7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'strategy': 'constant', 'constant': 50.0},\n",
       " {'strategy': 'quantile', 'quantile': 0.75},\n",
       " {'strategy': 'mean'},\n",
       " {'strategy': 'median'}]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline = dummy.DummyRegressor(strategy='median')\n",
    "strategies = ['constant', 'quantile', 'mean', 'median', ]\n",
    "baseline_args = [{'strategy':s} for s in strategies]\n",
    "\n",
    "# additional args for constant and quantile\n",
    "baseline_args[0]['constant'] = 50.0\n",
    "baseline_args[1]['quantile'] = 0.75\n",
    "baseline_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "116599e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>constant</th>\n",
       "      <td>14,657.6847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile</th>\n",
       "      <td>10,216.3874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5,607.1979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>5,542.2252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "{\\centering\n",
       "\\begin{tabular}{lr}\n",
       "\\toprule\n",
       "{} &                  mse \\\\\n",
       "\\midrule\n",
       "constant &          14,657.6847 \\\\\n",
       "quantile &          10,216.3874 \\\\\n",
       "mean     &           5,607.1979 \\\\\n",
       "median   &           5,542.2252 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\n",
       "\\medskip}"
      ],
      "text/plain": [
       "                          mse\n",
       "constant          14,657.6847\n",
       "quantile          10,216.3874\n",
       "mean               5,607.1979\n",
       "median             5,542.2252"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# similar to ch 5, but using a list comprehension\n",
    "# process a single argument package (a dict)\n",
    "\n",
    "def do_one(**args):\n",
    "    baseline = dummy.DummyRegressor(**args)\n",
    "    baseline.fit(diabetes_train_ftrs, diabetes_train_tgt)\n",
    "    base_preds = baseline.predict(diabetes_test_ftrs)\n",
    "    return metrics.mean_squared_error(base_preds, diabetes_test_tgt)\n",
    "\n",
    "# gather all results via a list comprehension\n",
    "mses = [do_one(**bla) for bla in baseline_args]\n",
    "\n",
    "display(pd.DataFrame({'mse':mses}, index=strategies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c013644c",
   "metadata": {},
   "source": [
    "# 7.2 Additional Measures for Regression\n",
    "\n",
    "So far, we used *mean squared error* as our success measure in regression problems.  We have also modified MSE to the *root mean squared error* (RMSE) because the scale of MSE is a bit off compared to our predictions.  MSE is on the same scale as the squares of the errors; RMSE moves us back to the scale of the errors.  We've done this in an ad-hoc manner by applying square roots here and there.  However, RMSE is more commonly use, let's integrate RMSE more deeply into our `sklearn`-fu. (Seriously, what???) (what is `sklearn`-fu?)\n",
    "\n",
    "\n",
    "We develop the new regression evaluation metric in three steps.  We define an error measure, use the error to define a score, and use the score to create a scorer.  This is because, generally, `sklearn` wants to work with scores, where bigger is better.\n",
    "\n",
    "Remember: (1) for *errors* and *loss functions*, lower values are better and (2) for *scores*, higher values are better.  Therefore, we need an inverse relationship between our error measure and our score.  One of the easiest ways to do that is to negate the error.  Therefore, for RMSE, all our scores based on it will be negative, and being *better* means being closer to zero while still negative.  A way to think about this is like losing *less* money.\n",
    "\n",
    "The error and scoring functions have to receive three arguments: a fit model, predictors, and a target.  `sklearn` has a naming convention that \"smaller is better\" ends with `_error` or `_loss` and \"bigger is better\" ends with `_score`.  The `*_scorer` form is responsible for applying a model on features to make predictions and compare them with actual known values.  It quantifies the success using an error or score function.\n",
    "\n",
    "It is not necessary to define all three of these pieces.  We could pick and choose which RMS components we want to implement.  However, writing code for all three demonstrates how they are related."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af6d0f",
   "metadata": {},
   "source": [
    "## 7.2.1 Creating Our Own Evaluation Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "207358fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-59.9545, -60.4838, -62.1117, -72.6665, -68.2894])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rms_error(actual, predicted):\n",
    "    'root-mean-squared-error function '\n",
    "    # lesser values are better (a < b means a is better)\n",
    "    mse = metrics.mean_squared_error(actual, predicted)\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "def neg_rmse_score(actual, predicted):\n",
    "    ' rmse based score function '\n",
    "    # greater values are better (a < b means b is better)\n",
    "    return -rms_error(actual, predicted)\n",
    "\n",
    "def neg_rmse_scorer(mod, ftrs, tgt_actual):\n",
    "    ' rmse scorer suitable for scoring arg '\n",
    "    tgt_pred = mod.predict(ftrs)\n",
    "    return neg_rmse_score(tgt_actual, tgt_pred)\n",
    "\n",
    "knn = neighbors.KNeighborsRegressor(n_neighbors=3)\n",
    "skms.cross_val_score(knn,\n",
    "                     diabetes.data, diabetes.target,\n",
    "                     cv=skms.KFold(5, shuffle=True),\n",
    "                     scoring=neg_rmse_scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7941c7",
   "metadata": {},
   "source": [
    "The `hand_and_till_M_statistic` from earlier acted like a score and we turned it into a scorer with `make_scorer`.\n",
    "Here, we laid out all the `sklearn` subcomponents for RMSE: an error measure, a score, and a scorer.  `make_scorer` can be told to treat larger values as the *better* result with the `greater_is_better` argument."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4c641e",
   "metadata": {},
   "source": [
    "## 7.2.2 Other Built-in Regression Metrics\n",
    "\n",
    "The laundry list of metrics is available through `metrics.SCORERS.keys().`  We can check out the default metric for linear regression by looking at `help(lr.score)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "31d090bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "aa1e373d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Return the coefficient of determination :math:`R^2` of the', '        prediction.', '', '        The coefficient :math:`R^2` is defined as :math:`(1 - \\\\frac{u}{v})`,', '        where :math:`u` is the residual sum of squares ``((y_true - y_pred)', '        ** 2).sum()`` and :math:`v` is the total sum of squares ``((y_true -', '        y_true.mean()) ** 2).sum()``. The best possible score is 1.0 and it', '        can be negative (because the model can be arbitrarily worse). A', '        constant model that always predicts the expected value of `y`,', '        disregarding the input features, would get a :math:`R^2` score of', '        0.0.', '', '        Parameters', '        ----------', '        X : array-like of shape (n_samples, n_features)', '            Test samples. For some estimators this may be a precomputed', '            kernel matrix or a list of generic objects instead with shape', '            ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted``', '            is the number of samples used in the fitting for the estimator.', '', '        y : array-like of shape (n_samples,) or (n_samples, n_outputs)', '            True values for `X`.', '', '        sample_weight : array-like of shape (n_samples,), default=None', '            Sample weights.', '', '        Returns', '        -------', '        score : float', '            :math:`R^2` of ``self.predict(X)`` wrt. `y`.', '', '        Notes', '        -----', '        The :math:`R^2` score used when calling ``score`` on a regressor uses', \"        ``multioutput='uniform_average'`` from version 0.23 to keep consistent\", '        with default value of :func:`~sklearn.metrics.r2_score`.', '        This influences the ``score`` method of all the multioutput', '        regressors (except for', '        :class:`~sklearn.multioutput.MultiOutputRegressor`).', '        ']\n",
      "Return the coefficient of determination :math:`R^2` of the\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "#help(lr.score) # for full output\n",
    "print(lr.score.__doc__.splitlines())\n",
    "print(lr.score.__doc__.splitlines()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bf9a1d",
   "metadata": {},
   "source": [
    "The default metric for linear regression is $R^2$.  $R^2$ is the default metric for all regressors.  The other major built-in performance evaluation metrics for regressors are mean absolute error, mean squared error, and median absolute error.\n",
    "\n",
    "In both mean absolute error (MAE) and mean squared error (MSE), the mean part means to divide by the number of examples.  MAE penalizes large and small differences from *actual* by the same amount as the size of the error.  Therefore, if we are off by 10 we get a penalty of 10.  However, MSE penalizes bigger errors more: being off by 10 generates a penalty of 100.  If two predictions are off by 5, the contributes to MAE are $5 + 5 = 10$.  However, with MSE, the contributions from two errors of 5 are $5^2 + 5^2 = 25 + 25 = 50$.  Therefore, with MAE, we could have 10 data points off by 5, two points off by 25, or one point off by 50.  For MSE, we could only have one point off by about 7 since $7^2$ = 49.\n",
    "\n",
    "Median absolute error protetcs from single large errors overwhelming other well-behaved errors.  If we are OK with a few real bad errors, as long  as the rest of the predictions are on track, MAE may be a good fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5680bb36",
   "metadata": {},
   "source": [
    "## 7.2.3 $R^2$\n",
    "\n",
    "Let's define $R^2$ in the manner the `sklearn` computes it.  We describe $R^2$ in terms of two models.  The first is *our model of interest*.  From it, we can calculate how well we do with our model using the *sum of squared errors.*\n",
    "\n",
    "$$ SSE_{ours} = \\Sigma_i(our\\_preds_{i} - actual_{i})^2 $$ \n",
    "\n",
    "$$ SSE_{mean} = \\Sigma_i(mean - actual_{i})^2 $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "379ed653",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_preds  = np.array([1, 2, 3])\n",
    "mean_preds = np.array([2, 2, 2])\n",
    "actual     = np.array([2, 3, 4])\n",
    "\n",
    "sse_ours = np.sum((our_preds - actual)**2)\n",
    "sse_mean = np.sum((mean_preds - actual)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895266db",
   "metadata": {},
   "source": [
    "With these two components, we can compute $R^2$ just like `sklearn` describes in its documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "475a8fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual r2: 0.40\n"
     ]
    }
   ],
   "source": [
    "r_2 = 1 - (sse_ours / sse_mean)\n",
    "print(f'manual r2:{r_2:5.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efbb474",
   "metadata": {},
   "source": [
    "The formula referenced by the `sklearn` docs is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbdf7e3",
   "metadata": {},
   "source": [
    "$$ R^2 = 1 - \\frac{SSE_{ours}}{SSE_{mean}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eec026c",
   "metadata": {},
   "source": [
    "$\\frac{SSE_{ours}}{SSE_{mean}}$ is the ratio between how well we do versus how well a simple model does, when both models are measured in terms of the sum of squared errors.  The specific baseline model is the `dummy.DummyRegressor(strategy='mean')` that we saw at the start of the chapter.  For example, if the errors of our predictor were 2500 and the errors o fthe mean were 10000, the ratio between the two would be \\frac{1}{4} and we would ahve $R^2 = 1 - \\frac{1}{4} = \\frac{3}{4} = 0.75$  We are *normalizing* or rescaling, our model's performance to a model that always predicts the mean target value.  What is the *one minus* that ratio?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f6dcd",
   "metadata": {},
   "source": [
    "### 7.2.3.1 An Interpretation of $R^2$ for the Machine Learning World\n",
    "\n",
    "The term $\\frac{SSE_{ours}}{SSE_{mean}}$ will be between zero and one.  If the linear regression uses only a constant term it will be identical to the mean and the value will be 1.  At the low end, if there linear regression makes no errors on the data, it will be zero.  \n",
    "\n",
    "However, our model could be *worse* than the mean.  If we have a worse-than-mean model, and we use `sklearn`'s formula for $R^2$, then we have a *negative* value.  \n",
    "\n",
    "How can we think about `sklearn`'s $R^2$ in a reasonable way?  The ratio between the SSEs gives us a normalized performance versus a standard, baseline model.  Under the hood, the SSE is the same as our mean squared error but without the mean.  If we divide both SSEs in the ratio by *n*, we get\n",
    "\n",
    "$$ R^2 = 1 - \\frac{\\frac{SSE_{ours}}{n}}{\\frac{SSE_{mean}}{n}} = 1 - \\frac{MSE_{ours}}{MSE_{mean}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987ec1c1",
   "metadata": {},
   "source": [
    "We have really been working with ratios of MSEs in disguise.  To ease our interpration of the right-hand side, let's get ride of the 1-."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db18bae",
   "metadata": {},
   "source": [
    "$$ R^2 = 1 - \\frac{SSE_{ours}}{SSE_{mean}} = 1 - \\frac{MSE_{ours}}{MSE_{mean}} $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba7ff2",
   "metadata": {},
   "source": [
    "$$ 1 - R^2 = \\frac{SSE_{ours}}{SSE_{mean}} = \\frac{MSE_{ours}}{MSE_{mean}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d9185",
   "metadata": {},
   "source": [
    "We can view $ 1 - R^2 $ (for arbitrary machine learning models) as a MSE that is normalized by the MSE we get from a simple, baseline model that predicts the mean.  If we have two models of interest and if we compare (divide) the $ 1 - R^2 $ of our model 1 and the $1 - R^2 $ of our model 2, we get:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9c0d65",
   "metadata": {},
   "source": [
    "$$ \\frac{1 - R^2_{M1}}{1 - R^2_{M2}} = \\frac{\\frac{MSE_{M1}}{MSE_{mean}}}{\\frac{MSE_{M2}}{MSE_{mean}}} = \\frac{MSE_{M1}}{MSE_{M2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d36064",
   "metadata": {},
   "source": [
    "This is the ratios of MSEs or SSEs between the two models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046f534",
   "metadata": {},
   "source": [
    "### 7.2.3.2 A Cold Dose of Reality: sklearn's $R^2$\n",
    "\n",
    "Let's compute a few simple $R^2$ values manually and with `sklearn`.  We compute `r2_score` from actuals and test set predictions from a simple predict-the-mean model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1de1fea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.014016723490579253\n"
     ]
    }
   ],
   "source": [
    "baseline = dummy.DummyRegressor(strategy='mean')\n",
    "\n",
    "baseline.fit(diabetes_train_ftrs, diabetes_train_tgt)\n",
    "base_preds = baseline.predict(diabetes_test_ftrs)\n",
    "\n",
    "# r2 is not symmetric because true values have priority\n",
    "# are are used to compute target mean\n",
    "base_r2_sklearn = metrics.r2_score(diabetes_test_tgt, base_preds)\n",
    "print(base_r2_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d41d93",
   "metadata": {},
   "source": [
    "Now, let's look at those values with some manual computations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "2b9c71f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn train-mean model SSE(on test): 622398.970317905\n",
      " manual train-mean model SSE(on test): 622398.970317905\n",
      " manual test-mean model SSE(on test): 613795.5675675675\n"
     ]
    }
   ],
   "source": [
    "# sklearn-train-mean to predict test tgts\n",
    "base_errors = base_preds - diabetes_test_tgt\n",
    "sse_base_preds = np.dot(base_errors, base_errors)\n",
    "\n",
    "# train-mean to predict test targets\n",
    "train_mean_errors = np.mean(diabetes_train_tgt) - diabetes_test_tgt\n",
    "sse_mean_train = np.dot(train_mean_errors, train_mean_errors)\n",
    "\n",
    "# test-mean to predict test targets (Danger Will Robinson!)\n",
    "test_mean_errors = np.mean(diabetes_test_tgt) - diabetes_test_tgt\n",
    "sse_mean_test    = np.dot(test_mean_errors, test_mean_errors)\n",
    "\n",
    "print('sklearn train-mean model SSE(on test):', sse_base_preds)\n",
    "print(' manual train-mean model SSE(on test):', sse_mean_train)\n",
    "print(' manual test-mean model SSE(on test):', sse_mean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11688b",
   "metadata": {},
   "source": [
    "In the third option, we calculated the mean of the *test* set and looked at my error against the test targets.  Not surprisingly, since we are teaching to the test, we do a bit better than the other cases.  Let's see what happens if we use the taught-to-the-test values as our baseline for computing `r2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "416bbabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[219.  70. 202. 230. 111.  84. 242. 272.  94.  96.  94. 252.  99. 297.\n",
      " 135.  67. 295. 264. 170. 275. 310.  64. 128. 232. 129. 118. 263.  77.\n",
      "  48. 107. 140. 113.  90. 164. 180. 233.  42.  84. 172.  63.  48. 108.\n",
      " 156. 168.  90.  52. 200.  87.  90. 258. 136. 158.  69.  72. 171.  95.\n",
      "  72. 151. 168.  60. 122.  52. 187. 102. 214. 248. 181. 110. 140. 202.\n",
      " 101. 222. 281.  61.  89.  91. 186. 220. 237. 233.  68. 190.  96.  72.\n",
      " 153.  98.  37.  63. 184. 144. 150. 280. 125.  59.  65. 281. 277. 167.\n",
      "  90.  72. 178.  88. 270. 101. 197.  97.  53.  71. 262.  52. 102.]\n",
      "145.54054054054055\n",
      "[ -73.4595   75.5405  -56.4595  -84.4595   34.5405   61.5405  -96.4595\n",
      " -126.4595   51.5405   49.5405   51.5405 -106.4595   46.5405 -151.4595\n",
      "   10.5405   78.5405 -149.4595 -118.4595  -24.4595 -129.4595 -164.4595\n",
      "   81.5405   17.5405  -86.4595   16.5405   27.5405 -117.4595   68.5405\n",
      "   97.5405   38.5405    5.5405   32.5405   55.5405  -18.4595  -34.4595\n",
      "  -87.4595  103.5405   61.5405  -26.4595   82.5405   97.5405   37.5405\n",
      "  -10.4595  -22.4595   55.5405   93.5405  -54.4595   58.5405   55.5405\n",
      " -112.4595    9.5405  -12.4595   76.5405   73.5405  -25.4595   50.5405\n",
      "   73.5405   -5.4595  -22.4595   85.5405   23.5405   93.5405  -41.4595\n",
      "   43.5405  -68.4595 -102.4595  -35.4595   35.5405    5.5405  -56.4595\n",
      "   44.5405  -76.4595 -135.4595   84.5405   56.5405   54.5405  -40.4595\n",
      "  -74.4595  -91.4595  -87.4595   77.5405  -44.4595   49.5405   73.5405\n",
      "   -7.4595   47.5405  108.5405   82.5405  -38.4595    1.5405   -4.4595\n",
      " -134.4595   20.5405   86.5405   80.5405 -135.4595 -131.4595  -21.4595\n",
      "   55.5405   73.5405  -32.4595   57.5405 -124.4595   44.5405  -51.4595\n",
      "   48.5405   92.5405   74.5405 -116.4595   93.5405   43.5405]\n",
      "613795.5675675675\n"
     ]
    }
   ],
   "source": [
    "print(diabetes_test_tgt)\n",
    "print(np.mean(diabetes_test_tgt))\n",
    "print(test_mean_errors)\n",
    "print(sse_mean_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "25bb2ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.014016723490578809"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - (sse_base_preds / sse_mean_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de161355",
   "metadata": {},
   "source": [
    "Let's compare with the `r2` score we calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "16fdfed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.014016723490579253\n",
      "-0.014016723490578809\n"
     ]
    }
   ],
   "source": [
    "print(base_r2_sklearn)\n",
    "print(1 - (sse_base_preds / sse_mean_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ca2c2",
   "metadata": {},
   "source": [
    "`sklearn`'s $R^2$ is calculating its base model--the mean model--from the true values we are testing against.  \n",
    "\n",
    "We are not comparing the performance of `my_model.fit(train)` and `mean_model.fit(train)`.  With `sklearn`'s $R^2$ we are comparing `my_model.fit(train)` with `mean_model.fit(test)` and evaluating them against `test`.  Since this is counterintuitive, let's draw it out the long way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2e468fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5529.689797906013\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R^2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>Norm_MSE</th>\n",
       "      <th>1-R^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNeighborsRegressor</th>\n",
       "      <td>0.3722</td>\n",
       "      <td>3,471.4194</td>\n",
       "      <td>0.6278</td>\n",
       "      <td>0.6278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LinearRegression</th>\n",
       "      <td>0.4849</td>\n",
       "      <td>2,848.2953</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>0.5151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "{\\centering\n",
       "\\begin{tabular}{lrrrr}\n",
       "\\toprule\n",
       "{} &                  R\\textasciicircum 2 &                  MSE &             Norm\\_MSE &                1-R\\textasciicircum 2 \\\\\n",
       "\\midrule\n",
       "KNeighborsRegressor &               0.3722 &           3,471.4194 &               0.6278 &               0.6278 \\\\\n",
       "LinearRegression    &               0.4849 &           2,848.2953 &               0.5151 &               0.5151 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\n",
       "\\medskip}"
      ],
      "text/plain": [
       "                                     R^2                  MSE  \\\n",
       "KNeighborsRegressor               0.3722           3,471.4194   \n",
       "LinearRegression                  0.4849           2,848.2953   \n",
       "\n",
       "                                Norm_MSE                1-R^2  \n",
       "KNeighborsRegressor               0.6278               0.6278  \n",
       "LinearRegression                  0.5151               0.5151  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "# WARNING! Don't try this at home, boys and girls!\n",
    "# We are fitting on the *test* set... to mimic the behavior\n",
    "# of sklearn R^2\n",
    "#\n",
    "\n",
    "testbase = dummy.DummyRegressor(strategy='mean')\n",
    "testbase.fit(diabetes_test_ftrs, diabetes_test_tgt)\n",
    "testbase_preds = testbase.predict(diabetes_test_ftrs)\n",
    "testbase_mse = metrics.mean_squared_error(testbase_preds,\n",
    "                                          diabetes_test_tgt)\n",
    "\n",
    "models = [neighbors.KNeighborsRegressor(n_neighbors=3),\n",
    "          linear_model.LinearRegression()]\n",
    "\n",
    "results = co.defaultdict(dict)\n",
    "for m in models:\n",
    "    preds = (m.fit(diabetes_train_ftrs, diabetes_train_tgt)\n",
    "              .predict(diabetes_test_ftrs))\n",
    "        \n",
    "    mse = metrics.mean_squared_error(preds, diabetes_test_tgt)\n",
    "    r2 = metrics.r2_score(diabetes_test_tgt, preds)\n",
    "    results[get_model_name(m)]['R^2'] = r2\n",
    "    results[get_model_name(m)]['MSE'] = mse\n",
    "    \n",
    "print(testbase_mse)\n",
    "\n",
    "df = pd.DataFrame(results).T\n",
    "df['Norm_MSE'] = df['MSE'] / testbase_mse\n",
    "df['1-R^2'] = 1-df['R^2']\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d73482",
   "metadata": {},
   "source": [
    "Therefore, $1 - R^2$ computed by `sklearn` is equivalent to the MSE of our model normalized by the *fit-to-the-test-sample* mean model.  If we *knew* the mean of our test targets, the value tells us how well we would do in comparison to predicting that known mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111cb29f",
   "metadata": {},
   "source": [
    "### 7.2.3.3 Recommendations on $R^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a54150",
   "metadata": {},
   "source": [
    "There are some reasons to not use $R^2$ unless you are an advanced user and believe you know what you are doing.\n",
    "\n",
    "1.  $R^2$ has a lot of scientific and statistical baggage.  Any statements that include 'ercent' or 'linear' or 'explained' should be viewed with *extreme* skepticism when applied to `sklearn`'s $R^2$.\n",
    "\n",
    "2. There are a number of formulas for $R^2$ `sklearn` uses one of them.  The multiple formulas for $R^2$ are equivalent when using a linear model with an intercept, but there are other scenarios where they are *not* equivalent.\n",
    "\n",
    "3.  $R^2$ has a simple relationship to a very weird thing: a *normalized MSE computed on a test-sample-trained mean model*.  We can avoid the baggabe by going straight to the alternative.\n",
    "\n",
    "Instead of $R^2$ we will use MSE or RMSE.  If we *really* want to normalize the scores, we can compare our regression model with a training-set-trained mean model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6e138b",
   "metadata": {},
   "source": [
    "# 7.3 Residual Plots\n",
    "\n",
    "Let's step back and look at some graphical techniques for evaluating regressors.  We will develop a regression analog of confusion matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbfb7b0",
   "metadata": {},
   "source": [
    "## 7.3.1 Error Plots\n",
    "\n",
    "Let's graph an actual, true target value against a predicted value.  The graphical distance between the two represents our error.  Therefore, if the actual value was 27.5 and we predicted 31.5, we'd plot the point (x = 27.5, y = 31.5) on axes labeled (Reality, Predicted).  Perfect Predictions would be points alon the line $y = x$ because for each output, we'd be predicting exactly that value.  For now, we keep the directions of our errors.  Predicting too high makes a positive error and vice-a-versa.  The second graph will swap the predicted-actual axes.  Therefore, our point will become (x = 31.5, y=27.5): (Predicted, Reality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "536879ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "{\\centering\n",
       "\\begin{tabular}{lrr}\n",
       "\\toprule\n",
       "{} &  predicted &  actual \\\\\n",
       "\\midrule\n",
       "0 &          4 &       3 \\\\\n",
       "1 &          2 &       5 \\\\\n",
       "2 &          9 &       7 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\n",
       "\\medskip}"
      ],
      "text/plain": [
       "   predicted  actual\n",
       "0          4       3\n",
       "1          2       5\n",
       "2          9       7"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ape_df = pd.DataFrame({'predicted' : [4, 2, 9],\n",
    "                       'actual'    : [3, 5, 7]})\n",
    "\n",
    "ape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fd643d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "{\\centering\n",
       "\\begin{tabular}{lrrr}\n",
       "\\toprule\n",
       "{} &  predicted &  actual &  error \\\\\n",
       "\\midrule\n",
       "0 &          4 &       3 &      1 \\\\\n",
       "1 &          2 &       5 &     -3 \\\\\n",
       "2 &          9 &       7 &      2 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\n",
       "\\medskip}"
      ],
      "text/plain": [
       "   predicted  actual  error\n",
       "0          4       3      1\n",
       "1          2       5     -3\n",
       "2          9       7      2"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ape_df['error'] = ape_df['predicted'] - ape_df['actual']\n",
    "                        \n",
    "ape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9ee1d5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "{\\centering\n",
       "\\begin{tabular}{lrrr}\n",
       "\\toprule\n",
       "{} &  predicted &  actual &  error \\\\\n",
       "example &            &         &        \\\\\n",
       "\\midrule\n",
       "0       &          4 &       3 &      1 \\\\\n",
       "1       &          2 &       5 &     -3 \\\\\n",
       "2       &          9 &       7 &      2 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\n",
       "\\medskip}"
      ],
      "text/plain": [
       "         predicted  actual  error\n",
       "example                          \n",
       "0                4       3      1\n",
       "1                2       5     -3\n",
       "2                9       7      2"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ape_df.index.name = 'example'\n",
    "ape_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "3ab4c575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def regression_errors(figsize, predicted, actual, errors='all'):\n",
    "    ''' figsize -> subplots;\n",
    "        predicted/actual data -> columns in a DataFrame\n",
    "        errors -> 'all' or sequence of indices \n",
    "    '''\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize,\n",
    "                             sharex=True, sharey=True)\n",
    "    df = pd.DataFrame({'actual':actual,\n",
    "                       'predicted': predicted})\n",
    "    \n",
    "    for ax, (x,y) in zip(axes, it.permutations(['actual',\n",
    "                                                'predicted'])):\n",
    "        # plot the data as '.'; perfect as y=x line\n",
    "        ax.plot(df[x], df[y], '.', label='data')\n",
    "        ax.plot(df['actual'], df['actual'], '-',\n",
    "               label='perfection')\n",
    "        ax.legend()\n",
    "        \n",
    "        ax.set_xlabel('{} Value'.format(x.capitalize()))\n",
    "        ax.set_ylabel('{} Value'.format(y.capitalize()))\n",
    "        ax.set_aspect('equal')\n",
    "        \n",
    "    axes[1].yaxis.tick_right()\n",
    "    axes[1].yaxis.set_label_position('right')\n",
    "    \n",
    "    # show connecting bars from data to perfect\n",
    "    # for all or only those specified?\n",
    "    if errors == 'all':\n",
    "        errors = range(len(df))\n",
    "    if errors:\n",
    "        acts = df.actual.iloc[errors]\n",
    "        preds = df.predicted.iloc[errors]\n",
    "        axes[0].vlines(acts, preds, acts, 'r')\n",
    "        axes[1].hlines(acts, preds, acts, 'r')\n",
    "        \n",
    "regression_errors((6, 3), ape_df.predicted, ape_df.actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f892b78",
   "metadata": {},
   "source": [
    "The orange line is an omnisicient model, where the predicted value is the true actual value.  The error there si zero.  Flipping the axes results in flipping the dataoints over the line $y = x$.  We can apply this to our diabetes dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "152cf044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "preds = (lr.fit(diabetes_train_ftrs, diabetes_train_tgt)\n",
    "           .predict(diabetes_test_ftrs))\n",
    "\n",
    "regression_errors((8, 4), preds, diabetes_test_tgt, errors=[-20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097bdca3",
   "metadata": {},
   "source": [
    "The left-hand graph answers the question \"compared to reality, how did we do?\" The right-hand graph answers, 'for a given prediction, how did we do?'  The difference is similar to that between sensitivity (and specificity) being calcluated with respect to the *reality of sick*, while precision is calculated with respect to a *prediction of sick*.  When the actual value ranges from 200 to 250, we seem to consistently predict low.  When the predicted value is near 200, we have real values ranging from 50 to 300."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca4b260",
   "metadata": {},
   "source": [
    "## 7.3.2 Residual Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fe8935",
   "metadata": {},
   "source": [
    "We will not talk about *residual plots*.  The error of our predictions can be calculated as follows: $ error = predicted - actual $.  However, for *residual plots* the equation is $ residuals = actual - predicted $.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "539b1f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "      <th>error</th>\n",
       "      <th>resid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>example</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "{\\centering\n",
       "\\begin{tabular}{lrrrr}\n",
       "\\toprule\n",
       "{} &  predicted &  actual &  error &  resid \\\\\n",
       "example &            &         &        &        \\\\\n",
       "\\midrule\n",
       "0       &          4 &       3 &      1 &     -1 \\\\\n",
       "1       &          2 &       5 &     -3 &      3 \\\\\n",
       "2       &          9 &       7 &      2 &     -2 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\n",
       "\\medskip}"
      ],
      "text/plain": [
       "         predicted  actual  error  resid\n",
       "example                                 \n",
       "0                4       3      1     -1\n",
       "1                2       5     -3      3\n",
       "2                9       7      2     -2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ape_df = pd.DataFrame({'predicted' : [4, 2, 9],\n",
    "                       'actual'    : [3, 5, 7]})\n",
    "ape_df['error'] = ape_df['predicted'] - ape_df['actual']\n",
    "ape_df['resid'] = ape_df['actual'] - ape_df['predicted']\n",
    "ape_df.index.name = 'example'\n",
    "display(ape_df)\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1e844d",
   "metadata": {},
   "source": [
    "When talking about *errors* we interpret that value as how much we over- or undershot by.  Any error of 2 means our prediction was over by 2.  We can think about it as *what happened*.  With residuals, we think about what adjustment we need to do to *fix up* our prediction.  A residual of -2 means that we need to subtract 2 to get the right answer.\n",
    "\n",
    "With residuals, we are thinking about the adjustment we need to do to *fix up* our prediction.  A residual of -2 means that we need to subtract 2 to get to the right answer.\n",
    "\n",
    "Residual plots are made by graphing the predicted value against the residual for the prediction.  Therefore, we need a slight variation of the right graph above (predicted versus actual) but written in terms of *residuals*, not *errors*.  We will take the residual values, which are the signed distance from predicted back to actual, and graph them against their predicted value.\n",
    "\n",
    "For example, if we predict 31.5 for an example that is actually 27.5, the residual is -4.0.  So we have a point at (*x* = predicted = 31.5, *y* = residual = -4.0).  These can be thought of as *what's left over after we make a prediction*.  What's left over is sometimes called a *residue.* \n",
    "\n",
    "We are making two graphs: (1) actual against predicted and (2) predicted against residual.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5da9399a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def regression_residuals(ax, predicted, actual,\n",
    "                         show_errors=None, right=False):\n",
    "    ''' figsize -> subplots;\n",
    "        predicted/actual data -> columns of a DataFrame\n",
    "        errors -> 'all' or sequence of indices\n",
    "    '''\n",
    "    df = pd.DataFrame({'actual':actual,\n",
    "                       'predicted':predicted})\n",
    "    df['error'] = df.actual - df.predicted\n",
    "    ax.plot(df.predicted, df.error, '.')\n",
    "    ax.plot(df.predicted, np.zeros_like(predicted), '-')\n",
    "    \n",
    "    if right:\n",
    "        ax.yaxis.tick_right()\n",
    "        ax.yaxis.set_label_position('right')\n",
    "        ax.set_xlabel('Predicted Value')\n",
    "        ax.set_ylabel('Residual')\n",
    "        \n",
    "    if show_errors == 'all':\n",
    "        show_errors = range(len(df))\n",
    "    if show_errors:\n",
    "        preds = df.predicted.iloc[show_errors]\n",
    "        errors = df.error.iloc[show_errors]\n",
    "        ax.vlines(preds, 0, errors, 'r')\n",
    "        \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax1.plot(ape_df.predicted, ape_df.actual, 'r.', # pred vs actual\n",
    "         [0, 10], [0, 10], 'b-')              \n",
    "ax1.set_xlabel('Predicted')\n",
    "ax1.set_ylabel('Actual')\n",
    "regression_residuals(ax2, ape_df.predicted, ape_df.actual,\n",
    "                    'all', right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d021a80e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-c5078dced31e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mregression_residuals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiabetes_test_tgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m36\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_right\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-162-38c4f8cc1b4d>\u001b[0m in \u001b[0;36mregression_residuals\u001b[1;34m(ax, predicted, actual, show_errors, right)\u001b[0m\n\u001b[0;32m      8\u001b[0m                        'predicted':predicted})\n\u001b[0;32m      9\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactual\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "regression_residuals(ax, preds, diabetes_test_tgt, [0,10,20,30,35,36], on_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc507a13",
   "metadata": {},
   "source": [
    "Now, we can compare two different learners based on their residual plots.   We can use a proper train-test split, so these residuals are called *predictive residuals*.  In a traditional stats class, the plain vanilla residuals are computed from the training set (sometimes called *in sample*).  That's not our normal method for evaluation: we prefer to evaluate against a test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c9dbc493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtoAAAF6CAYAAAAnGv9AAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+60lEQVR4nO3de5xddXnv8e93JgmIgMRAkUsSSEErUKVOxPFUPXBqrXBoES8clKrtEVGrbW31tFhbRKzV02rVnuIF0XppRFCkUKtFsXipdYQMInIpNUYiIVEgDEK8MEnmOX+stclm2HtmX9ba6/Z5v155ZWbtvdf+/fae9axnPb/fWssRIQAAAADZGiu6AQAAAEAdkWgDAAAAOSDRBgAAAHJAog0AAADkgEQbAAAAyAGJNgAAAJADEu0Gsv1027cW3Y46sH2T7eOLbkcvFvvebX/E9l9m8D6H2Q7bS4ZdF1B1tm+z/cyi24Fs2V5le7vt8S6Pn2v7HzN6r7B9RBbrwuiRaNdYtwAfEV+LiMcV0ab50mC0Iw1Y99r+D9tPLbpdvYqIoyPiy1mv1/aXbf88/Vzutv0Z2wcNs84yfe8AHi6Nh2H7tLZlS9Jlh6W/fyT9/bi25xxhu+tNMWz/ju1daTy5z/a3bZ+ca2dKJP3MZtP+32P7i7Z/aZh1RsQPImLviNiVVTtRTyTaGJkFKpwXR8TekvaXdLWkT+Xw3rZdtb/316SfyxGS9pb0joLbAyB/90h6c7dKadtz+h19+kYaT/aT9F5Jn7S930AtXMAi7c7dAvuZv077f4ikOyR9aHStQpNVLfFABmwfb3tz2++32X697Rts/9j2xbb3bHv8ZNvXt1Wcn9D22Nm2v2f7fts32z617bHfsf112++yvU3SuQu1KyJ2Slon6RDbB6TreJTtD9neavsO23/ZCuS2x22/M634ft/2a9qnLKRV4bfa/rqkn0paY/uX0mrGPbZvnVc5Ointw/3pe70+Xb6/7c+m/b/H9tdaSXv7qIHtPWy/2/aW9N+7be/R/pnbfp3tO9P+/G4v31dE3CvpnyQd29bWQfox/3v/FdvXpc+7WFL7d/47tv+9vR1uG760/T9tfyutjt1u+9xu7U/XtTF9n+/bPqOXfgN1Y/vx6TbwwgWe9q+SZiX99gLP+aikJ9j+7/22ISLmJH1c0iMlHZm2aw/b77D9A9s/sv1+249oa/efpDFri+0z58WCj9h+n+3P2f6JpBNsH2z7Utt3pf39g7Z1HWd7fRo7fmT7b9Ple9r+R9vb0lh7re0D08cOtn1FGu822H552/rOtf3p9LX3SfqdRfr/M0mX6KHxdJD2PmSKnO3DbX8ljXNfVFI4aq3jIbE3Xda+7zjO9jfSfm+1/fe2l3Vqf7f4jvIi0UbLaZKeLelwSU9QGqxs/4qkD0t6haQVkj4g6YpWAinpe5KeLulRkt4s6R/90CkOT5G0UdKBkt66UAPSwPISSdskzaSLPyJpp5Kq7q9IepakM9PHXi7pRCUB80mSntNhtS+WdJakfSTdJemLkj4h6RcknS7pvbaPSp/7IUmviIh9JB0j6d/S5a+TtFnSAWk//kxSp2HaN0qaTNvzREnHSfrztscfo+RzOkTSyySdb3t5908kYXuFpOdK2pD+/sgB+9G+zmVKkvePS3q0klGE5y3WljY/UfJd7Sfpf0p6le3ndHifR0r6O0knpu35b5Ku7+N9gFqw/SRJV0r6/Yi4aIGnhqS/kPQm20u7POenkv5Ki8TULu0Yl/S7knZI2pQufrukxyqJXUcoiVHnpM9/tqQ/lvTM9LHjO6z2RWlb9pH0H5L+WdK30/X8mqTX2v6N9LnvkfSeiNhX0i8qSXol6aVK4uNKJfuaV0r6WfrYJ5XE4IMlPV/SX9n+H23vf4qkTyuJR+sW6f8jJb1Qu+Pp2IDtne8TkqaVJNhvSfvTq12S/ih97VPTNvxel+cuGt9RLiTaaPm7iNgSEfcoCTrHpsvPkvSBiPhmROyKiI9KekBJQqmI+FT6urmIuFjSd5UkmC1bIuL/RcTOtJLQyWm271USVF8u6fkRsTOtZpwk6bUR8ZOIuFPSu5QkllJycPCeiNgcETNKdhbzfSQibkqr5c+WdFtE/EPanm9JulTSC9Ln7pB0lO19I2ImIq5rW36QpNURsSOd69wp0T5D0nkRcWdE3KXkwOPFbY/vSB/fERGfk7Rd0kJzpv/O9o8l3a0kAP9+uvzkAfvRblLSUknvTtvzaUnXLtCWh4iIL0fEd9Lv/QZJF0nqVl2bk3SM7UdExNaIuKnX9wFq4umSrpD0koj47GJPjogrlBQGzlzgaR+QtMr2iT22YTKNsz9XMg3ttyPiTttWEuf/KCLuiYj7lSTx7XH2H9I4+lN1Hpm8PCK+nlbLf1nSARFxXkTMRsRGSR9sW98OSUfY3j8itkfEVNvyFZKOSPc10xFxn+2Vkn5V0p9GxM8j4npJFyo50G/5RkT8UxqPuu1nXp/2/35JT9Pu2PzkAdv7INur0vX8RUQ8EBFfVbIf7Una16k0nt+m5LvtFk97ie8oERJttPyw7eefKpkTLEmrJb0uHdK6Nw1UK5VUFmT7Jd49reReJUfY+7et6/Ye3vuSiNhPSbX4RkkTbe+9VNLWtvV/QEkVV2kb2tff6b3al62W9JR5fTlDSaVZSiq6J0nalA4Btk7K/Bsl1Y8vOJkCcXaXfhys3RUipT8f3Pb7tjThb2n/nDv5g4h4lJIRhuWSDh2yH/Pbese8A4ZNHZ7Xke2n2L46HWr9sZLq0/7znxcRP5H0v9LHt9r+Fw95EhJQQa+U9B/tJ07bPsPJyXnbbX++w2v+XMko2Z4dHlNEPKCkcvqW9uVOri7UWm/7Qe1UGmeXK0n6n54uP0DSXpKm2+LJv6bLpcHi7MHz4tOfKYnvUjKa91hJ/5lOD2mdlPlxJRX/TzqZovLXaUX/YEmtA4CWTUqqzwu1ab53pP0/TElRp1XkGLS97Q6WNJPGu/Y29sT2Y51MT/yhk+kvf6UO8TTVS3xHiZBoYzG3S3prROzX9m+viLjI9molR/6vkbQiDWI3SnLb67ueCT9fRNytpLJybjr95HYl1fP9295734g4On3JVu1OPqXkAOBhq53Xl6/M68veEfGq9P2vjYhTlCTy/6R0iDAi7o+I10XEGkm/JemPbf9ah/faoiRot6xKlw0lIr6j5MSn89Pq00D9mGerkrnw7d/Vqraff6Jk5ytJsv0YPdQnlOysV6YHA+/XQ7/39vZfGRG/rmRU4D+V/M0ATfJKJdXnd7UWRMS6dLvdOyIeVpWOiC8qOcDvNoVAkv5ByXSJ57a97mtt6z16/gsiYrukV0l6cTo18G4liefRbfHkUZGcOCgNFme/Py8+7RMRJ6Xv/92IeKGS+PR/JX3a9iPTkbU3R8RRSqaYnaykar1F0qNt79P2HquUnNDY6f0XFBE/kPSHkt7jZB76QO2dt9qtkpbPW75QPB3X7gMZSXqfkth4ZCRTVP5M3eNpL/EdJUKiXX9LnZxk0vrX77WNPyjplWkF07Yf6eREuH2UnEwTSoY45eTkvmOGaWxE3KqkqvEnEbFV0hckvdP2vrbHbP+id58AdImkP7R9iJOz5/90kdV/VtJjbb/Y9tL035OdnKC0LK0wPSoidki6T8mUh9bJoEekSemPlcynm+uw/osk/bntA2zvr2SOYybXUVVy8tOBShL9gfoxzzeUzH3/g/T1z9VDp/x8W9LRto91cmLsufNev4+SKtPPnVxm7EWdGm37QNunpDugB5RMl+nUHqDO7lcyde0ZtjtNcevmjZL+pNuD6QjZm7R47Jv/unuUTL84J53u8UFJ77L9C5KUxtTWHOVLJP1uGl/2UjJ/fCHXSLrf9p/afoSTk9aPsf3kdN2/bfuA9H3vTV8zZ/sE27+cJqH3KZkiMRcRtyuZ9/22dB/2BCVV5oFja3oQs0VJYWeg9s5b3yZJ65VcLWaZ7adJ+s22p/yXpD3TfedSJaMVe7Q9vk/a5+1ORvxe1andfcR3lAiJdv19Tkm1ovXv3H5eHBHrlcyb/nslJyhuUHqiZETcLOmdSpK2HymZm/f1DNr8N5LOSoP+SyQtk3Rz+v6fVlIZlZKdwxck3SDpW0r6ulNJItypL/crOZnydCVB9odKKhStgPdiSbelQ3evVDIdQ0rOzL9KSZL4DUnvjYirO7zFXyoJtjdI+o6k69T/Jbg6iohZJSfl/MUQ/Zi/vucq+S7vUTK94zNtj/+XpPOU9Pu7kv593ip+T9J5tu9XckDRraoypuREqi3p+/x3ddmJAHUWydWDfl3SibbfssjTW6/5upJEcCEXKamo9uvdkk5KE9c/VRLbp9K4cZXSqRUR8XklJzRf3XpO+voHurR5l5Jq9LGSvq+kYn6hkhMdpeSA4ybb25XEtNPTedWPURLf75N0i6SvKJlOIiUnLx6mJI5cJulNEXHVAH1u9zdKDmKWDNje+V6k5OT/e5Qc/Hys9UBE/FhJzLxQSSX+J0pO7mx5ffr6+5Xs1y5eoN2LxneUi6PjOV1A9Tg5Kej9EbF60ScDAPpm+/FKpgjuMe+cEwAdUNFGZaXDfCc5uXPaIUqqCJcV3S4AqBPbpzq51vZyJaNn/0ySDfSGRBtVZiWX0JtRMnXkFqXXfgUAZOYVku5Uct+EXWL6F9Azpo4AAAAAOaCiDQAAAOSg30u9FWb//fePww47rOhmAMDITU9P3x0RByz+zOERawE0VR6xtjKJ9mGHHab169cX3QwAGDnbPd9lbljEWgBNlUesZeoIAAAAkINMEm3bH7Z9p+0b25ada/sO29en/05qe+wNtjfYvrXt7lMAAABAbWRV0f6IkrsnzfeuiDg2/fc5SbJ9lJI72h2dvua96S1XAQAAgNrIJNGOiK8que1oL06R9MmIeCAivq/klq7HZdEOAAAAoCzynqP9Gts3pFNLlqfLDpF0e9tzNqfLHsb2WbbX215/11135dxUAAAANNj+rbwz/XfWsCvMM9F+n6RflHSspK2S3tnvCiLigohYGxFrDzhgJFe2AgAAQDPd3co7038XDLvC3BLtiPhRROyKiDlJH9Tu6SF3SFrZ9tRD02UAAABAbeSWaNs+qO3XUyW1rkhyhaTTbe9h+3BJR0q6Jq92AAAAAEXI5IY1ti+SdLySuS2bJb1J0vG2j5UUkm6T9ApJioibbF8i6WZJOyW9OiJ2ZdEOAAAAoCwySbQj4oUdFn9ogee/VdJbs3hvAAAAoIy4MyQAAACQAxJtAABKanrTjM6/eoOmN80U3RQAA8hk6ggAAMjW9KYZnXHhlGZ3zmnZkjGtO3NSE6uXL/5CAKVBRRsAgJKZ3jSjd1/1X5rdOae5kHbsnNPUxm1FNwtAn6hoAwBQIq1K9gM75hSSxiwtXTKmyTUrim4agD6RaAMAUCJTG7dpdmeaZEv61SP212uf+VimjQAVxNQRAABKZHLNCi1bMqZxS8uWjpFkAxVGRRsAgBKZWL1c686c1NTGbZpcs4IkG6gwEm0AAEpmYvVyEmygBpg6AgAAAOSARBsAAADIAYk2AAAYGe52iSZhjjYAoBDTm2Y44a9huNslmoZEO2PsOABgcSRczdS6Rnj73S753lFnJNoZYscBAL0h4Wqm1jXCd+yc426XaAQS7Qyx4wCA3pBwNRPXCEfTkGhniB0HAPSGhKu58rhGONM2UVYk2hlixwEAveOmLMgC0zZRZiTaGWPHAQDA6Ext3KbZ2Z2a8xjTNlE6XEcbAAAMrajrY0+uWaFlc7s0HruYtonSoaINAACGUuT0jYnVy7Xulks0te9KTb7tbKrZKBUSbQAAMJSir7o1sX2LJrZvkUiyUTJMHQEAAENpXXVr3GL6BtCGijYAABgKV90COiPRBgAAQ+OqW8DDMXUEANAYRV0ZA0AzUdEGADQCNzYBMGpUtAEAjdDpyhgAkCcSbQBAI3BlDACjxtQRAEAjcGUMAKNGog0AaAyujAFglJg6AgAAAOSARBsAAADIAYk2AAAAkAMSbQAAACAHJNpARXGHOwAAyo2rjgAVxB3uAAAoPyraQAVNbdym2dmd3OEOAIASI9EGKmhyzQotm9ul8djFHe4AACgppo4AFTSxernW3XKJpvZdqcm3nc20EQCVNb1phrt1orYySbRtf1jSyZLujIhj0mWPlnSxpMMk3SbptIiYsW1J75F0kqSfSvqdiLgui3YATTKxfYsmtm+R2DEBGJGsk2LON0HdZTV15COSnj1v2dmSvhQRR0r6Uvq7JJ0o6cj031mS3pdRGwAAQE5aSfE7v3CrzrhwKpMrHk1t3KbZnXOcb4LayiTRjoivSrpn3uJTJH00/fmjkp7TtvxjkZiStJ/tg7JoBwAAyEceSfHkmhVatmRM4xbnm6CW8pyjfWBEbE1//qGkA9OfD5F0e9vzNqfLtmoe22cpqXpr1apV+bUUAAAsqJUU79g5l1lSPLF6udadOckcbZTF/rbXt/1+QURcMMwKR3IyZESE7RjgdRdIukCS1q5d2/frAQBANvJKiidWLyfBRlncHRFrs1xhnon2j2wfFBFb06khd6bL75C0su15h6bLgMJw1jsALI6kGOhPntfRvkLSS9OfXyrp8rblL3FiUtKP26aYlBq3vK6nYU7w4W8CAAB0k9Xl/S6SdLySuS2bJb1J0tslXWL7ZZI2STotffrnlFzab4OSy/v9bhZtyBuXIKqvTif49PLd8jcBoAiMwAHVkUmiHREv7PLQr3V4bkh6dRbvO0qDJmMov8k1K7RkPDnBZ3y89xN8+JsAMGoc4APVwi3Ye8QliGou4qH/94C/CQCjNrVxm2Znd3LdaaAiuAV7j7gEUX1NbdymnXOhkLRrLnquTPM3AWDUJtes0LK5XdoxFlq6dCkH+EDJkWj3gbOt62mYa8OW5W+COZtAM0ysXq51t1yiqX1XavJtZ7O9AyVHoo3Gq3plmjmbQLNMbN+iie1bJLZzoPRItAGVpzI9CE7KBACgnDgZEqg4TsoEAKCcqGgDFVf1qS8AANQViTZQA1We+gIAQF0xdQQoKW7vDjQT2z5QH1S0MRJcfq4/XEkEaCa2faBeqGgjd60dxzu/cKvOuHCqY5WGCs5DdbqSCID6Y9sH6oWKNnK32OXnylzBKaoSP8xNdABUF9s+UC8k2sjdYjuOqY3bNDu7U3MeK9V1oIs8AMjrSiJM4QHKjasIAfVCoo3cLbbjmFyzQsvmdmnHWGjp0qWlqeAUfSOYrK8kUuaRAwC7cRUhoD5ItDESC+04JlYv17pbLtHUvis1+bazc9vB9FvNrdsQbtEHDgAANA2JNkphYvsWTWzfIuWYZPdbza3bEG7dDhwAYBSYcodhkGijEQat5tZpCLduBw4AkDem3GFYJNpoBKq5iTodOABA3phyh2GRaKMRqOYC5cbwPMqIIg2GRaKNXJVp50k1FygnhudRVhRpMCwSbeSGnSeAXjA8jzKjSINhcAt25IZbCfeG28+j6VrD8+NWYcPzbIcA8kBFG7lhbtviqPoDxQ/Psx0CyAuJNnJT9M6zChgyBxJFDs+zHQLIC4k2csXctoVR9QeKx3aIQZTpZH+UF4k2UCCq/kDx2A7RL6YboVck2kDBqPoDxWM7RD+YboRecdURAACAPpThSjmoBiraAAAAfWC6EXpFog0AANCnUU434sTL6iLRBgAAtVG3pJQTL6uNRBsAANRCHZNSTrysNk6GzAC37gUAoHidktKq48TLaqOiPaQ6Hj0DAFBFdbz5ECdeVhuJ9pAY0hmNus25AwBkr65JKdd5ry4S7SHV8ei5bBg1AIBqG2WxhKQUZUKiPaS6Hj2XCaMG+WPEAEBeKJagyUi0M8DRc74YNcgXO0EAeaJYgiYj0UbpMWqQL3aCAPJEsQRNRqKNSmDUID/sBAHkiWIJmiz3RNv2bZLul7RL0s6IWGv70ZIulnSYpNsknRYRXIQaKAA7QQB5o1iCphpVRfuEiLi77fezJX0pIt5u++z09z8dUVsAzMNOEACA7BV1Z8hTJH00/fmjkp5TUDvQJ+6CCQDNxn4A6N0oKtoh6Qu2Q9IHIuICSQdGxNb08R9KOrDTC22fJeksSVq1atUImoqFjPLqFFxuDkCVZRHDyhgHuUoRam5/2+vbfr8gzVsHNopE+2kRcYftX5D0Rdv/2f5gRESahD9M2rkLJGnt2rUdn4PRGcXVKaY3zejS6zbr09ObtXMXgbwqypgQAEXJIhkta2GDqxSh5u6OiLVZrjD3RDsi7kj/v9P2ZZKOk/Qj2wdFxFbbB0m6M+92YHh5X51ieu+DdcaFU3pgx5xaR1W9BHKSvGJR4QIeKotkdFQJbb/bL1cpAvqTa6Jt+5GSxiLi/vTnZ0k6T9IVkl4q6e3p/5fn2Q5kI++rU0ztu1KzO3cn2ZYWDeRVTPLqdmBAhQt4qCyS0VEltP1uv1nvB+oWD4H58q5oHyjpMtut9/pERPyr7WslXWL7ZZI2STot53Y8BBv24PK8OsXkfbc/uGMZH7NesHalnvukQxd8v6oleVkeGEzvfbCm9l2pyU0zhfaZChfwUFkko6O67OYg229W+4EqFkqAfuWaaEfERklP7LB8m6Rfy/O9u+m2YZN8F29i+5a+dyxVS/KmNm7T7OxOzXlsqAOD6U0zOuPxp2l2bFzLLpwqdAfFdbiBh8siGc1iHYvt24rcfqtWKAEG0bg7Q3basCVxVF0S/e5YqpbkTa5ZoWVzuzQ7JnlsXMv3WjbQeqY2btPs2PjQCXtWuA43UD69VoyL2n6rVigBBlHUdbQL09qwx717/m+35BvVMLF6uV59whGVSPQmVi/XObf9m8YitGsudN5nbxroWrSthH08drGDAtBR2fdtrULJHz/rcRS4UFuNq2h3q4ByVI1RmVn6CM3ZCg0+XDqxernW3XJJMkf7bWezgwLwMKOuGA8yBZPRMNRd4xJt6eEbdtWmH4wCc9bzM3nf7Vo2t0s7lowNtfOb2L5FE9u3SHw/ADoY5b6NExuBzhqZaHfCUfVuBMx8TWzfklSjX3deow5kOHgDRm9U+zZObBwcsbHeSLTxMATM/E1s36KJE44ouhkjw8EbUG+c2DgYYmP9NT7RruOR5LB9ImAiaxy8AfXGFMzBEBvrr9GJdh2PJLPoEwETWePgDVhYFYo+vVyTu6xtLytiY/01OtGu45FkVn0iYCJLHLwB3VWh6FOFNlZRHrGxCgdtTdLoRLuOR5J17BPqgYM3oLMqFH2q0MaqyjI2ckBUPo1OtOtYZatjnwCgKKOoDlahQFKFNoIDojJqdKIt1bPKVsc+AcCojao6WIUCSRXaCA6IyqjxiTYAAJ2MsjpYhQJJFdrYdBwQlQ+JNoBS4AQelA3VQVQRB0TlQqINoHCcwIMyojpYXxzYY1RItIEaqPpOgxN40KtR/61THawfDuwxSiTaJVb15AmjUYedBkP06EUd/tbrrgr7LQ7sMUok2iXFDqW7KgTyUarDToMhevSiDn/rZZVFXK3KfmvYA3v2QegHiXZJsUPprCqBfJTqUg1miB6LqcvfetksFFf7SSqrst8a5sCefRD6RaJdUuxQOqtKIB8lqsFoCv7W89EtrvabVFZpvzXogT37IPSLRLuk2KF0VqVAnrWFKktUg9EUVfpbr8oUg25xtd+ksgn7rSbvgzAYEu0R6yfwVmmHMipNCOSddKwsFd0oAF1VaYpBt7g6SFJZ9/1WU/dBGFxjE+0iKg1VCrxlVvdA3knHylLRjQLQVdWmGHSKqySVnTVxH4TBNTLRLirhrVrgRXkwXAlkZxSFlkG32bJNNyGpBIbTyES7qIS3bMlS2QJ6GZT1M6GyBGRjVIWWQbZZRj1RBWXdT5ZVIxPtohLeMiVLWQb0umx0Zd/JUVkChjfKQku/2+wo21aXuI3RKvt+sowamWgXmfCWJVnKKqDXaaNjag9Qf2UbWWw3qrbVKW5XQZ0OathP9q+RibZUnoS3KFkF9DptdGXeAQPIxvxCiySdf/WGUiRBoyoCFR2365R4LqZuBzXsJ/vX2ES76bIK6HXa6Mo0tQdAflqFljImQaMoAhUZt8v4meep6IOarLGf7B+JdoNlEdDrttFVfaSjTpWiOvUF5VS3JKhXRcbtpn3mVShG9Rtrq76fHDUSbQytrBtd0xK1OlWK6tQXlFcVkqC8FBW3m/aZl70YRazNH4m2mpeQNUETg0edKkV16gvKq+xJUB018TMvazFKItYuxvYfL/R4RPztYutofKLdT0JGQl4dTQwedaoU1akvKLdhkiD2CYMpc+LZNMTaRe0z7Aoan2j3mpA1sUJaZVkHj+lNM7r0us2ypOc+6dBSfvd1qhTVqS+oJ/YJqANi7cIi4s3DrqPxiXavCVmeFVKqItnLMnhMb5rRCy/4hmZ3hSTpU9ObddHLy7lTrVOlqE59Qf00cdQM9USsXZztPSW9TNLRkvZsLY+I/73YaxufaLcnZMv3WqapjdseXN4ur+GVhaoiJODDySp4TG3cph1pki2xUwWyVEScy+I9GXJ/OPZZqLGPS/pPSb8h6TxJZ0i6pZcXNj7RlnYn1QsNA+Y1vNKtKsKwZHlMrlmhpeN+sKLNThXIRhFxLqv3rNKQ+ygSYPZZqLkjIuIFtk+JiI/a/oSkr/XyQhLt1PyE9zPXbX5YYMpjeKVbVYRhyfKYWL1cF5311NLP0Qaqpog4l+V7VmHIfVQJMPus/DFiUKgd6f/32j5G0g8l/UIvLyTRTrUnvOPjY/rU+tu1cy5yPzLvVhUZZFiSjTA/VdihAlVTxPSLYd6zijF2auM2zc7u1JzHck2AmUqTr7KPGFRx2+jTBbaXS/oLSVdI2lvSOb28sNaJdj9ffHvCe8e9P9Mnr/nByI7MOyVx/Q5Lln0jBID5iph+Meh7VjXGTq5ZoWVzu7RjLLR06dLcEuAqTaWpojKPGFR12+hHRFyY/vgVSWv6eW1hibbtZ0t6j6RxSRdGxNuzXP8gX3wr4Z3eNKPPXLe58CPzblXUTgcQZd4IAaCbIkaL+omtrWVb7v1ZJWPsxOrlWnfLJZrad6Um33b2yItGyEaZRwyakH/Y7li9jojzFnttIYm27XFJ50v6dUmbJV1r+4qIuDmr9xjmiy/zkXm3A4gyb4QAUHadYqu0+yT5JWPWkvEx7dpVvRg7sX2LJrZvkUq0L0N/ypyXNCT/+Enbz3tKOlk9XnXEEbH4szJm+6mSzo2I30h/f4MkRcTbur1m7dq1sX79+p7fY3rTjH7+4d/Ur/o7wzYXAIa35njpJZcP9FLb0xGxNtsGddZvrB3Kx06RNn55NO8FIFe37/cU3XnqxaU6COhXr7HW9h6SroyI4xd77lgWDRvAIZJub/t9c7rsIWyfZXu97fV33XVXX28wsXq5fvmQRw3XSgAAACxq5aMfUekkO7V/K+9M/53V5Xl7STq0lxWW+mTIiLhA0gVSUmXp9/X7nvUvmbepDLI6u/eNl31H6775gwd/P+Mpq/TWU3+5/xUdf3zy/5e/PHBbsjKSM59L1F+g0gas8D9MRtvkQnO0yzZcX2d85hlhXzWIuztVtG1/R1IrDx2XdICSG9csqqhE+w5JK9t+PzRdVlpl2vCHPeGk1Zc773/gIctHP4koW0048xlAftpPiD//6g0PO+G89RzkhziejzLlMBV1ctvPOyX9KCJ29vLCohLtayUdaftwJQn26ZJeVFBbFlX0hp/lBtLelyXjY1oyJu2ak5aOW897Uk+jIKVVxTOfCX5AucyP9+ecfLTO++xNJH4jUsU4XnZF5zBVZvvR6Y/3z3toX9uKiHsWW0chiXZE7LT9GklXKinBfzgibiqiLb0ocsPPegNp78uuXXM6/bhVOni/R9Qi0avamc8EP6B85sf7z9+4lcRvhKoWx6uAg5ehTCsZ8LekVZJm0p/3k/QDSYcvtoLC5mhHxOckfa6o9+9HkRt+1hvI/L7U6XbiZb78UScEPyBfg4wYzY+RJx5zkK697R4SvxGpWhyvAg5eBhcRh0uS7Q9KuizNXWX7REnP6WUdpT4ZsiyK3PCz3EBaO51zTj5aMz+drWUQK+qGCVns0Al+QHYGHTHqFO8f95h9+tq+mRI2HG5807te/tY4eMnEZES8vPVLRHze9l/38kIS7R4UGTSz2kB62emwcxhMljt0ANkY9qZl7c/tJ/FjShhGpZ+/NQ5ehrbF9p9L+sf09zMkbenlhSTai+jnDzmvRDWLDWSxnQ47h8FluUMHkI1OI0ajKCYMEw8odnTHZ/Nwi+7X9z5YU/uu1OSmGT6z4b1Q0pskXZb+/tV02aJItBfRa9Ase6K62E6H+cKDYwoIUD7zR4wkjSRGDxoPyr4PKRKfTWcL/a1Nb5rRGY8/TbNj41p24RSf2ZDSq4v84SCvJdFeRK9Bs+yJ6mI7nXNOPppkcUBMAQHKqX3E6PyrN2QeoztVWdvjwfK9lvV8/e2y70Pajbq6XKXPZpQW2vdMbdym2SVL+cyGZPvdEfFa2/+sDrcbiYjfWmwdJNqL6DWJqkJVc6GdzsxPZ4dKFqf3PlhT827w0CRMAckfQ8foZHrTjKYOfoom77tdEws8L+sYvVCVtfV/P1XYKuxDpGKqy1X5bIrQbd/DZ5aZj6f/v2PQFZBo96CXJKoKVc32RKXTRjhosji998HJENUXbq3dsB7JXTkwdIxOHvy7WPk0LZvbpXULzEXNOkYvVmXttwpbhX2IVEx1uSqfTZnwmWUjIqbT/7/SWmZ7uaSVEXFDL+sg0c5QmauanRKVrDbCqX1XanZsvHZDVCR35cHQMTp58O/CY9oxFj0ls1n93SxWMeylojj/QL7VtjLf7r2oSmmZ969lxWeWHdtflvRbSvLmaUl32v56RPzxYq8l0W6ITonKq084IpONcPK+27Vsbpd2LBkrdIgq6+ozyV15MAyKTh78u5jdoaVzcyP9u1isYrjY450O5KXRnLA5DCqlaKhHRcR9ts+U9LGIeJNtKtrYLc9EZWL7Fq275RJNve68wgJvHtXnLD4zpp5kg507Onnw7+INb0/maK9+zsjff9AKeqcDeUmVOLinUooGWmL7IEmnSXpjXy/Mpz0om7wTlYntWzRxwhGZrrMfeVSfh/3Mhkn+SdAfjp07OplYvVwTW75ZdDP61u1AvrVsfMzacu/PNM01kIEyOE/SlZK+HhHX2l4j6bu9vJBEu0HqnKjkVbEf5jMbNPlnbjhQf90O5NedOalLr9usT09v1kXX/ECXXreZGAAULCI+JelTbb9vlPS8Xl5Loo1aKOPUgkGTf+aGA83Q6UB+YvVyTW3cpp27iAFAWdh+rKT3STowIo6x/QRJvxURf7nYa0m0KyrLqQV1maZQtor9oMk/J/4B+Sp7zCMGAKXzQUn/R9IHJCkibrD9CUkk2qM0quCd5dQCpinkq5X8T2+a0fk93tCnjNV5oEyGibXzY945Jx+tmZ/OlmpbIwYApbNXRFxju33Zzl5eSKKdkVEmrFlOLWCaQv4G+dsoW3UeKIuO21Mfr2+PebM753TO5TdqLqJ0hQZiAFAqd9v+RaW3Ybf9fElbe3nhWJ6tapJul2oaVqsSOr1p5sFlrWHFcWvoYcX2dY2Pj+mO9Cz3qur0eRUtr78NoImG3Z7aY96YrV1zwbYJYDGvVjJt5Jds3yHptZJe2csLqWhnJI85dd0qoVkOK7bW9ZnrNutT62/XJ6/5gT5T0bPcyzoNhvmWQHaG3Z7a4+fyvZbpvM/exLYJYEHpVUaeafuRSorUP5V0uqRNi72WRDsjecypW2haR5bDig+e5T6vslOGJLUfZZ0Gw3xLlP3kuyrJYntqj5+Pe8w+fDcAOrK9r5Jq9iGSLpd0Vfr76yTdIGndYusg0c5Q1nPqRlkJrUPVtcx9YL5lc5V1pKXKsi408H0A6OLjkmYkfUPSy5XcFdKSTo2I63tZAYl2iY2yElqHqmsd+oD6KetIC5A1Rm5QQ2si4pclyfaFSk6AXBURP+91BSTaJTfKaksdKjt16APqpcwjLU1CEpivrEdu+L5QEjtaP0TELtub+0myJRJtAMgVIy3Fq+L0naolmlmO3FTx+0JtPdH2fenPlvSI9HdLiojYd7EVkGgDFVK1nS8SjLTka3rvgzW170pNbprp+Dn3mwQWvZ1VMdHMcuSG6VYoi4gYH3YdJNpARVRx5wvkbXrTjM54/GmaHRvXsgunOm4X/SSBZdjOyphodjv4aF+e1cgN061QJyTaQEWUcecLFG1q4zbNLlm64HbRz/SdMmxnZUs0ux18dFr+6hOOGPr9qj7dqugREZQLiTb6QgBZfJg6L2Xb+QJl0Ot20ev0nSy3s0HjZdkSzW4HH3kelFR1ulUZRkRQLiTa6BkBpLdh6ryUbecLlEHW20VW6xs2Xg6SaOZVCOl28FHGg/+ii0FlGBFBuZBoN1i/AYkA0tswdZ6qWuUB8pTVdtEeE4edAjHqeJlnIaTbwUfZDv7LUAwq48EHikWi3VCDBCQCCJ8BUFf9xsTFChXL91qmMVtSjCRWdEvss6rwdjuYKdPBfxmKQWU7+EDxSLQbapCARADhMwDqqp+YuFhSPr1pRud99ibtmguNj1nnnHx07rGiUxGgDBXeUSqiENLpQKZMBx8oHol2Qw0akMo0b7AoBFGgfvqJiYsl5a3HQ1JEaOansw95fR4xsVMR4PyrNxRe4R2lURdCmnYgg8GQaDfUxOrlOufko/X5G7fq6IP21dTGbQ8uzxKBCEAV9JOkLZaUL/R43nOp29fVxKluoyyElGGqCsqPRLuhWkObszvn9LXv3i1L2mNp9okwgQhAVbRi02KFh8WS8oUeH2VMzLPCW7eRykE08UAG/SPRbqj2YC9JoXyCPoEIQFX0U21erHLa7fFRx8Q8KryMVCY4Zwe9INFuqFawbyXbY1IuQZ9A9FBUgYDyGkW1uQ4xkZHK3ThnB4sh0S6BIpKv9mC/fK9lmvnpbG7vTyBKUAUCym1U1eaqx0RGKoHekWgXrMjkq+rBPgujPMihCgSUWx2qzaPA5wT0jkS7YCRfxRn1QQ5VIKD88ixA1GnqGIUaoDck2gUj+SrOqA9yqAIBzcXUMaCZcku0bZ8r6eWS7koX/VlEfC597A2SXiZpl6Q/iIgr82pH2ZF8FaeIgxyqQEAzMXoJNFPeFe13RcQ72hfYPkrS6ZKOlnSwpKtsPzYiduXcltIi+SoGBzkARoXRS6CZipg6coqkT0bEA5K+b3uDpOMkfaOAtqDhOMgBMAoc2APNlHei/RrbL5G0XtLrImJG0iGSptqeszld9jC2z5J0liStWrUq56YCAJAfDuyB0tvf9vq23y+IiAuGWeFQibbtqyQ9psNDb5T0PklvUXLTwbdIeqek/93P+tPOXSBJa9eujWHaCgBAU5Xpiidlagswz90RsTbLFQ6VaEfEM3t5nu0PSvps+usdkla2PXxougwAAGSsTFc8KVNbgFEYy2vFtg9q+/VUSTemP18h6XTbe9g+XNKRkq7Jqx0AADRZpyue0BZgNPKco/3Xto9VMnXkNkmvkKSIuMn2JZJulrRT0qubfMURAADyVKYrnpSpLcAo5JZoR8SLF3jsrZLemtd7o3jMwQOAcijTFU/K1BZgFLgzJDJX9Tl4HCQAqJsyXfGkTG0B8kaijcxV+Q5oVT9IANBcFAmA8iHRRuaqPAevygcJAJqLIgFQTiTayFyZ5uD1W+Gp8kFCN1S5gPqjSACUE4k2clGGOXiDVHjKdJCQBapcxeDgBqNWxyIBUAck2qitQSs8ZThIyApVrtHj4AZFqFuRAKgLEm2MRBEVvjJVeIqqcJbpM2gKDm5QlDoVCYC6INFG7oqq8JWlwlNkhbMsn0GTcHADAGgh0UbuiqzwlaHCU3SFswyfQZNwcIM64rwDYDAk2shd0yt8Te9/E3FwgzrhvANgcCTayF3TK3xN7z+AaplfvS56VK5bu4AqINHGSDS9wtf0/gOohk7V6zKMylFVR1WRaKORqIwAwMN1ql6/+oQjCh+VK0tVHegXiTYah8oIAHTWrXpd9KhcGarqwCBItNE4VEYAoLOynlNS1nYBiyHRRuNQGQFQlCpMWyu6et1NWdsFLIREG41DZQRAEZi2BjQPiTYaicoIgFFj2hrQPGNFNwAAgCZoTVsbt5i2BjQEFW0AAEaAaWtA85BoYySqcAJQS5XaCqBamLYGNAuJNnJXpROAqtRWAABQbszRRu46nQBUVlVqKwAAKDcSbQxteu+Ddf7BT9H0ppmOj1fpBKCs2jq9aUbnX72h62cCAFVCTAMGw9QRDGV604zOePxpmh0b17ILpzpOtajSCUBZtJXpJwDqpBXTHtgxp/Ex67xTjtGLnrKq6GYBlUCijaFMbdym2SVLF70ubJVOABq2rVwrF0CdTG3cpgd2zCkk7ZwLnXP5jXrcY/YhrgE9YOoIhlKlaSGjwmcCoIwGnf4xuWaFxsf84O9zEZy/AvSIijaGUqVpIaPCZwKgbIaZ0jaxernOO+UYnXP5jZqL0DIKCEDPSLQxtCpNCxkVPhMAZTLslLYXPWWVHveYfSggAH0i0UYlcVMZAOhda0rbjp1zA09po4AA9I9EG5XDVT0AoD9MaQOKQaKNyuGqHgDQv1FWpBl1BBIk2qicLIZAAQD5YNQR2I1EG5XDECgAlBejjsBuJNqoJE7KAYByYtQR2I1EGwAAZIZRR2A3Em0AAJApRh2BBLdgBwAAAHJAog0AAADkgEQbAAAAyMFQibbtF9i+yfac7bXzHnuD7Q22b7X9G23Ln50u22D77GHeHwAAACirYSvaN0p6rqSvti+0fZSk0yUdLenZkt5re9z2uKTzJZ0o6ShJL0yfCwAAANTKUFcdiYhbJMn2/IdOkfTJiHhA0vdtb5B0XPrYhojYmL7uk+lzbx6mHQAAAEDZ5DVH+xBJt7f9vjld1m15R7bPsr3e9vq77rorl4YCAAAAkvZv5Z3pv7OGXeGiFW3bV0l6TIeH3hgRlw/bgIVExAWSLpCktWvXRp7vBQAA6m160ww30sFC7o6ItYs/rXeLJtoR8cwB1nuHpJVtvx+aLtMCywEAAHIxvWlGZ1w4pdmdc1q2ZEzrzpwk2Ubu8po6coWk023vYftwSUdKukbStZKOtH247WVKTpi8Iqc2AAAASJKmNm7T7M45zYW0Y+ecpjZuK7pJaIBhL+93qu3Nkp4q6V9sXylJEXGTpEuUnOT4r5JeHRG7ImKnpNdIulLSLZIuSZ8LAACQm8k1K7RsyZjGLS1dMqbJNSuKbhIaYNirjlwm6bIuj71V0ls7LP+cpM8N874AAAD9mFi9XOvOnGSONkZqqEQbAACgKiZWLyfBxkhxC3YAAAAgByTawIhMb5rR+Vdv0PSmmaKbAgAARoCpI8AIcFkpAACah4o2kLFOlWsuKwUAQPNQ0QYy1K1y3bqs1I6dc1xWCgCAhiDRBjLUqXLdOsudy0oBANAsJNpAhhaqXHNZKQAAmoVEG8gQlWsAANBCog1kjMo1AACQuOoIAABA37g3AnpBRRsAAKAP3BsBvaKiDQAA0AfujYBekWgDAAD0oXWFqXGLeyNgQUwdAQAA6ANXmEKvSLQBAAD6xBWm0AumjgAAgFLiyh6oOiraAACgdLiyB+qAijYAACgdruyBOiDRBgAApcOVPVAHTB0BAAClw5U9UAck2gAAoJS4sgeqjqkjAAAAQA5ItAEAAIAckGgDAAAAOSDRBnLGDRcAAGgmToYEcsQNFwAAaC4q2kCOuOECAADNRaIN5IgbLgAA0FxMHQFyxA0XAABoLhJtIGfccAEAgGZi6ggAAACQAxJtAAAAIAck2gAAAEAOSLQBAACAHJBoAwAAADkg0QYAAAByQKINAAAA5IBEGwAAAMgBiTYAAACQg6ESbdsvsH2T7Tnba9uWH2b7Z7avT/+9v+2xCdvfsb3B9t/Z9jBtAAAAAMpo2Ir2jZKeK+mrHR77XkQcm/57Zdvy90l6uaQj03/PHrINAAAAQOkMlWhHxC0RcWuvz7d9kKR9I2IqIkLSxyQ9Z5g2AAAAAGWU5xztw21/y/ZXbD89XXaIpM1tz9mcLuvI9lm219tef9ddd+XYVAAAADTc/q28M/131rArXLLYE2xfJekxHR56Y0Rc3uVlWyWtiohttick/ZPto/ttXERcIOkCSVq7dm30+3qg7qY3zWhq4zZNrlmhidXLi24OAABVdndErF38ab1bNNGOiGf2u9KIeEDSA+nP07a/J+mxku6QdGjbUw9NlwHo0/SmGZ1x4ZRmd85p2ZIxrTtzkmQbAIASyWXqiO0DbI+nP69RctLjxojYKuk+25Pp1UZeIqlbVRzAAqY2btPszjnNhbRj55ymNm4rukkAAKDNsJf3O9X2ZklPlfQvtq9MH3qGpBtsXy/p05JeGRH3pI/9nqQLJW2Q9D1Jnx+mDUBTTa5ZoWVLxjRuaemSMU2uWVF0kwAAQJtFp44sJCIuk3RZh+WXSrq0y2vWSzpmmPcFIE2sXq51Z04yRxsAgJIaKtEGUKyJ1ctJsAEAKCluwQ4AAADkgEQbAAAAyAGJNgAAAJADEm0AAAAgByTaAAAAQA5ItAEAAIAckGgDAAAAOSDRBgAAAHJAog0AAADkgEQbAAAAyAGJNgAAAJADR0TRbeiJ7bskbcpgVftLujuD9ZRdU/opNaev9LNe+unn6og4IM/GtBBr+9aUfkrN6Sv9rJdCY21lEu2s2F4fEWuLbkfemtJPqTl9pZ/1Uvd+1r1/LU3pp9ScvtLPeim6n0wdAQAAAHJAog0AAADkoImJ9gVFN2BEmtJPqTl9pZ/1Uvd+1r1/LU3pp9ScvtLPeim0n42bow0AAACMQhMr2gAAAEDuSLQBAACAHNQ+0bZ9m+3v2L7e9vp02aNtf9H2d9P/lxfdzn7Z/rDtO23f2LasY7+c+DvbG2zfYPtJxbW8P136ea7tO9Lv9HrbJ7U99oa0n7fa/o1iWt0/2yttX237Zts32f7DdHmtvtMF+lnH73RP29fY/nba1zenyw+3/c20TxfbXpYu3yP9fUP6+GGFdqBPxNrqbpcSsbZu3ymxtkSxNiJq/U/SbZL2n7fsryWdnf58tqT/W3Q7B+jXMyQ9SdKNi/VL0kmSPi/JkiYlfbPo9g/Zz3Mlvb7Dc4+S9G1Je0g6XNL3JI0X3Yce+3mQpCelP+8j6b/S/tTqO12gn3X8Ti1p7/TnpZK+mX5Xl0g6PV3+fkmvSn/+PUnvT38+XdLFRfehz/4Sayu6XS7Qzzpul8Ta+n2npY61ta9od3GKpI+mP39U0nOKa8pgIuKrku6Zt7hbv06R9LFITEnaz/ZBI2nokLr0s5tTJH0yIh6IiO9L2iDpuNwal6GI2BoR16U/3y/pFkmHqGbf6QL97KbK32lExPb016Xpv5D0PyR9Ol0+/zttfdeflvRrtj2a1uaGWFuB7VIi1qpm3ymxtjyxtgmJdkj6gu1p22elyw6MiK3pzz+UdGAxTctct34dIun2tudt1sIbXBW8Jh3G+3DbcHQt+pkOY/2KkqPy2n6n8/op1fA7tT1u+3pJd0r6opIq0b0RsTN9Snt/Huxr+viPJa0YaYOHQ6yt+N9rF7XbLluItfX5Tssca5uQaD8tIp4k6URJr7b9jPYHIxk7qN01Duvar9T7JP2ipGMlbZX0zkJbkyHbe0u6VNJrI+K+9sfq9J126Gctv9OI2BURx0o6VEl16JeKbVGuiLX1U8vtUiLWqmbfaZljbe0T7Yi4I/3/TkmXKfkCftQa+kn/v7O4FmaqW7/ukLSy7XmHpssqKSJ+lG5Uc5I+qN3DW5Xup+2lSgLiuoj4TLq4dt9pp37W9TttiYh7JV0t6alKhp6XpA+19+fBvqaPP0rSttG2dHDEWkk1+Xttqet2Sayt33faUsZYW+tE2/Yjbe/T+lnSsyTdKOkKSS9Nn/ZSSZcX08LMdevXFZJekp49PSnpx21DZJUzb37cqUq+Uynp5+npGcWHSzpS0jWjbt8g0vlhH5J0S0T8bdtDtfpOu/Wzpt/pAbb3S39+hKRfVzJP8mpJz0+fNv87bX3Xz5f0b2llrfSItdXeLrup6XZJrN2tLt9puWPtYmdLVvmfpDVKzqL9tqSbJL0xXb5C0pckfVfSVZIeXXRbB+jbRUqGfXYomXv0sm79UnJG7vlK5ix9R9Laots/ZD8/nvbjBiUbzEFtz39j2s9bJZ1YdPv76OfTlAxV3iDp+vTfSXX7ThfoZx2/0ydI+lbapxslnZMuX6NkB7ZB0qck7ZEu3zP9fUP6+Jqi+9BHX4m1Ud3tcoF+1nG7JNbW7zstdazlFuwAAABADmo9dQQAAAAoCok2AAAAkAMSbQAAACAHJNoAAABADki0AQAAgByQaAMA0DC2d9m+3vaNtj9le68h1vUR289Pf77Q9lELPPd42/9tgPe4zfb+85b9g+1XzFv2HNuf76WtwCiQaAMA0Dw/i4hjI+IYSbOSXtn+YNsd9foSEWdGxM0LPOV4SX0n2l1cJOn0ectOT5cDpUCiDQBAs31N0hFptflrtq+QdLPtcdt/Y/ta2ze0qsfpXRL/3vattq+S9AutFdn+su216c/Ptn2d7W/b/pLtw5Qk9H+UVtOfnt7V79L0Pa61/avpa1fY/oLtm2xfqOTGMfN9SdIvtd06/ZGSninpn2yfk67vRtsXpHdKfIj2Krnttba/3FqP7Q/bvsb2t2yfks3HjCYi0QYAoKHSyvWJSu4WKElPkvSHEfFYJXeH/HFEPFnSkyW9PL0996mSHifpKEkvUYcKte0DJH1Q0vMi4omSXhARt0l6v6R3pdX0r0l6T/r7kyU9T9KF6SreJOnfI+JoSZdJWjX/PSJil6RLJZ2WLvpNSV+OiPsk/X1EPDmt2D9C0sl9fCxvVHJb7uMknSDpb9IkHujbQENDAACg0h5h+/r0569J+pCShPmaiPh+uvxZkp7QNqf5UZKOlPQMSRelie4W2//WYf2Tkr7aWldE3NOlHc+UdFRbwXlf23un7/Hc9LX/Ynumy+svkvQOJQn76UpuMS5JJ9j+E0l7SXq0pJsk/XOXdcz3LEm/Zfv16e97Kkn0b+nx9cCDSLQBAGien0XEse0L0mT3J+2LJP1+RFw573knZdiOMUmTEfHzDm3pxX9IOsj2E5UcKJxue09J75W0NiJut32ukmR5vp3aPbLf/riVVOJv7bkXQBdMHQEAAJ1cKelVtpdKku3HplMovirpf6VzuA9SMr1ivilJz0inmsj2o9Pl90vap+15X5D0+61fbB+b/vhVSS9Kl50oaXmnBkZESLpY0kclfT5N2FtJ891pdbzbVUZukzSR/vy8ef3+/da8btu/0uX1wKJItAEAQCcXSrpZ0nW2b5T0ASUj4ZdJ+m762MckfWP+CyPiLklnSfqM7W8rSYalZPrGqa2TISX9gaS16cmWN2v31U/erCRRv0nJFJIfLNDOiyQ9Mf1fEXGvkvnhNypJmq/t8ro3S3qP7fWSdrUtf4ukpZJuSN//LQu8N7AgJweDAAAAALJERRsAAADIAYk2AAAAkAMSbQAAACAHJNoAAABADki0AQAAgByQaAMAAAA5INEGAAAAcvD/AXGei5URGXHbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = linear_model.LinearRegression()\n",
    "knn = neighbors.KNeighborsRegressor()\n",
    "\n",
    "models = [lr, knn]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5),\n",
    "                         sharex=True, sharey=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "for model, ax, on_right in zip(models, axes, [False, True]):\n",
    "    preds = (model.fit(diabetes_train_ftrs, diabetes_train_tgt)\n",
    "                  .predict(diabetes_test_ftrs))\n",
    "    \n",
    "    regression_residuals(ax, preds, diabetes_test_tgt, [0,10,20,30,35,36], on_right)\n",
    "    \n",
    "axes[0].set_title('Linear Regression Residuals')\n",
    "axes[1].set_title('k-NN-Regressor Residuals');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab140a5",
   "metadata": {},
   "source": [
    "Since the two models predict different values for our point of interest, it shows up at different spots on the horizontal *x* axis.  With linear regression, the value is predicted a hint under 250.  With the *k*-NN-R model, the value is predicted to be a bit above 250.  In both cases, it is underpredicted.  Remeber, residuals tell us how to fix up the prediction.  We need to ADD a bit to these predictions).  Teh actual value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "69d269cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280.0\n"
     ]
    }
   ],
   "source": [
    "print(diabetes_test_tgt[-20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0cda23a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([219.,  70., 202., 230., 111.,  84., 242., 272.,  94.,  96.,  94.,\n",
       "       252.,  99., 297., 135.,  67., 295., 264., 170., 275., 310.,  64.,\n",
       "       128., 232., 129., 118., 263.,  77.,  48., 107., 140., 113.,  90.,\n",
       "       164., 180., 233.,  42.,  84., 172.,  63.,  48., 108., 156., 168.,\n",
       "        90.,  52., 200.,  87.,  90., 258., 136., 158.,  69.,  72., 171.,\n",
       "        95.,  72., 151., 168.,  60., 122.,  52., 187., 102., 214., 248.,\n",
       "       181., 110., 140., 202., 101., 222., 281.,  61.,  89.,  91., 186.,\n",
       "       220., 237., 233.,  68., 190.,  96.,  72., 153.,  98.,  37.,  63.,\n",
       "       184., 144., 150., 280., 125.,  59.,  65., 281., 277., 167.,  90.,\n",
       "        72., 178.,  88., 270., 101., 197.,  97.,  53.,  71., 262.,  52.,\n",
       "       102.])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_test_tgt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b439f2",
   "metadata": {},
   "source": [
    "If either model predicted 280, the residual would be zero.  In classicial stats, when looking at the residual plots, you are trying to diagnose if the assumptions of linear regression are violated.  However, here we use linear regression as a black box prediction method.  therefore, we are concerned about trends among the residual s with respect to the predicted values.  Potential trends are what these graphs give us a chance to evaluate.  At the low end of the predicted values for the linear regression model, we have pretty consistent **negative error** (*positive residual*).  This means that when we predict a small value, we are undershooting.  We also see undershooting in the predicted values around 200 to 250.  \n",
    "\n",
    "For *k*-NN-R, there is a wider spread among the negative errors, while the positive errors are more clumped around the zero error line.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa784b",
   "metadata": {},
   "source": [
    "# 7.4 A First Look at Standardization\n",
    "\n",
    "Broadly, when normalzing, we take different measurements and put them directly on comparable footing.  This often involves two steps: (1) adjusting the center of the data and (2) adjusting the scale of the data.\n",
    "\n",
    "Some learning methods *require* normalization before we can reasonably press 'Go!'.  Second we are using a common form of normalization called *standardization*.  When we *standardize* our data, we do two things: (1) we *center* the data around zero and (2) we scale the data so it has a standard deviation of 1.  To acommplish this we do two things (1) subtract the mean and (2) divide by the standard deviation.  \n",
    "\n",
    "The standard deviation is a close friend of variance.  We get standard deviation by taking the square root of variance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7fc5f885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>std-ized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.5000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.6706</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "{\\centering\n",
       "\\begin{tabular}{lrr}\n",
       "\\toprule\n",
       "{} &                    x &             std-ized \\\\\n",
       "\\midrule\n",
       "mean &               2.5000 &               0.0000 \\\\\n",
       "std  &               4.6706 &               1.0000 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\n",
       "\\medskip}"
      ],
      "text/plain": [
       "                        x             std-ized\n",
       "mean               2.5000               0.0000\n",
       "std                4.6706               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1D standardization\n",
    "# place evenly spaced values in a dataframe\n",
    "xs = np.linspace(-5, 10, 20)\n",
    "df = pd.DataFrame(xs, columns=['x'])\n",
    "\n",
    "# center ( - mean) and scale (/ std)\n",
    "df['std-ized'] = (df.x - df.x.mean()) / df.x.std()\n",
    "\n",
    "# show original and new data; compute statistics\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 3))\n",
    "sns.stripplot(data=df)\n",
    "display(df.describe().loc[['mean', 'std']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2edbae",
   "metadata": {},
   "source": [
    "That's all well and good, things get far more interesting in two dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b50e2421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.     -4.2105 -3.4211 -2.6316 -1.8421 -1.0526 -0.2632  0.5263  1.3158\n",
      "  2.1053  2.8947  3.6842  4.4737  5.2632  6.0526  6.8421  7.6316  8.4211\n",
      "  9.2105 10.    ]\n",
      "[ 9.043  22.5423 30.5935 30.2829 18.002  24.4295 39.8169 28.6401 41.5708\n",
      " 44.8184 40.5933 40.7796 44.4235 42.3288 57.9457 51.5387 62.5439 49.377\n",
      " 69.3971 60.8655]\n"
     ]
    }
   ],
   "source": [
    "# 2 1d standardizations\n",
    "xs = np.linspace(-5, 10, 20)\n",
    "ys = 3*xs + 2 + np.random.uniform(20, 40, 20)\n",
    "print(xs)\n",
    "print(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4e26c01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.0000</td>\n",
       "      <td>9.0430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.2105</td>\n",
       "      <td>22.5423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.4211</td>\n",
       "      <td>30.5935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.6316</td>\n",
       "      <td>30.2829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.8421</td>\n",
       "      <td>18.0020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.0526</td>\n",
       "      <td>24.4295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.2632</td>\n",
       "      <td>39.8169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5263</td>\n",
       "      <td>28.6401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.3158</td>\n",
       "      <td>41.5708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.1053</td>\n",
       "      <td>44.8184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.8947</td>\n",
       "      <td>40.5933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.6842</td>\n",
       "      <td>40.7796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.4737</td>\n",
       "      <td>44.4235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.2632</td>\n",
       "      <td>42.3288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.0526</td>\n",
       "      <td>57.9457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.8421</td>\n",
       "      <td>51.5387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.6316</td>\n",
       "      <td>62.5439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.4211</td>\n",
       "      <td>49.3770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>9.2105</td>\n",
       "      <td>69.3971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10.0000</td>\n",
       "      <td>60.8655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "{\\centering\n",
       "\\begin{tabular}{lrr}\n",
       "\\toprule\n",
       "{} &                    x &                    y \\\\\n",
       "\\midrule\n",
       "0  &              -5.0000 &               9.0430 \\\\\n",
       "1  &              -4.2105 &              22.5423 \\\\\n",
       "2  &              -3.4211 &              30.5935 \\\\\n",
       "3  &              -2.6316 &              30.2829 \\\\\n",
       "4  &              -1.8421 &              18.0020 \\\\\n",
       "5  &              -1.0526 &              24.4295 \\\\\n",
       "6  &              -0.2632 &              39.8169 \\\\\n",
       "7  &               0.5263 &              28.6401 \\\\\n",
       "8  &               1.3158 &              41.5708 \\\\\n",
       "9  &               2.1053 &              44.8184 \\\\\n",
       "10 &               2.8947 &              40.5933 \\\\\n",
       "11 &               3.6842 &              40.7796 \\\\\n",
       "12 &               4.4737 &              44.4235 \\\\\n",
       "13 &               5.2632 &              42.3288 \\\\\n",
       "14 &               6.0526 &              57.9457 \\\\\n",
       "15 &               6.8421 &              51.5387 \\\\\n",
       "16 &               7.6316 &              62.5439 \\\\\n",
       "17 &               8.4211 &              49.3770 \\\\\n",
       "18 &               9.2105 &              69.3971 \\\\\n",
       "19 &              10.0000 &              60.8655 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\n",
       "\\medskip}"
      ],
      "text/plain": [
       "                      x                    y\n",
       "0               -5.0000               9.0430\n",
       "1               -4.2105              22.5423\n",
       "2               -3.4211              30.5935\n",
       "3               -2.6316              30.2829\n",
       "4               -1.8421              18.0020\n",
       "5               -1.0526              24.4295\n",
       "6               -0.2632              39.8169\n",
       "7                0.5263              28.6401\n",
       "8                1.3158              41.5708\n",
       "9                2.1053              44.8184\n",
       "10               2.8947              40.5933\n",
       "11               3.6842              40.7796\n",
       "12               4.4737              44.4235\n",
       "13               5.2632              42.3288\n",
       "14               6.0526              57.9457\n",
       "15               6.8421              51.5387\n",
       "16               7.6316              62.5439\n",
       "17               8.4211              49.3770\n",
       "18               9.2105              69.3971\n",
       "19              10.0000              60.8655"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'x':xs, 'y':ys})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "bfc46549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.6058</td>\n",
       "      <td>-1.9987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.4368</td>\n",
       "      <td>-1.1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.2677</td>\n",
       "      <td>-0.6284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.0987</td>\n",
       "      <td>-0.6482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.9297</td>\n",
       "      <td>-1.4290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.7606</td>\n",
       "      <td>-1.0204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.5916</td>\n",
       "      <td>-0.0419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.4226</td>\n",
       "      <td>-0.7526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.2535</td>\n",
       "      <td>0.0696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.0845</td>\n",
       "      <td>0.2761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.0074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.4226</td>\n",
       "      <td>0.2510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.5916</td>\n",
       "      <td>0.1178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.7606</td>\n",
       "      <td>1.1108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.9297</td>\n",
       "      <td>0.7034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0987</td>\n",
       "      <td>1.4031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.2677</td>\n",
       "      <td>0.5659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.4368</td>\n",
       "      <td>1.8389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.6058</td>\n",
       "      <td>1.2964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "{\\centering\n",
       "\\begin{tabular}{lrr}\n",
       "\\toprule\n",
       "{} &                    x &                    y \\\\\n",
       "\\midrule\n",
       "0  &              -1.6058 &              -1.9987 \\\\\n",
       "1  &              -1.4368 &              -1.1404 \\\\\n",
       "2  &              -1.2677 &              -0.6284 \\\\\n",
       "3  &              -1.0987 &              -0.6482 \\\\\n",
       "4  &              -0.9297 &              -1.4290 \\\\\n",
       "5  &              -0.7606 &              -1.0204 \\\\\n",
       "6  &              -0.5916 &              -0.0419 \\\\\n",
       "7  &              -0.4226 &              -0.7526 \\\\\n",
       "8  &              -0.2535 &               0.0696 \\\\\n",
       "9  &              -0.0845 &               0.2761 \\\\\n",
       "10 &               0.0845 &               0.0074 \\\\\n",
       "11 &               0.2535 &               0.0193 \\\\\n",
       "12 &               0.4226 &               0.2510 \\\\\n",
       "13 &               0.5916 &               0.1178 \\\\\n",
       "14 &               0.7606 &               1.1108 \\\\\n",
       "15 &               0.9297 &               0.7034 \\\\\n",
       "16 &               1.0987 &               1.4031 \\\\\n",
       "17 &               1.2677 &               0.5659 \\\\\n",
       "18 &               1.4368 &               1.8389 \\\\\n",
       "19 &               1.6058 &               1.2964 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\n",
       "\\medskip}"
      ],
      "text/plain": [
       "                      x                    y\n",
       "0               -1.6058              -1.9987\n",
       "1               -1.4368              -1.1404\n",
       "2               -1.2677              -0.6284\n",
       "3               -1.0987              -0.6482\n",
       "4               -0.9297              -1.4290\n",
       "5               -0.7606              -1.0204\n",
       "6               -0.5916              -0.0419\n",
       "7               -0.4226              -0.7526\n",
       "8               -0.2535               0.0696\n",
       "9               -0.0845               0.2761\n",
       "10               0.0845               0.0074\n",
       "11               0.2535               0.0193\n",
       "12               0.4226               0.2510\n",
       "13               0.5916               0.1178\n",
       "14               0.7606               1.1108\n",
       "15               0.9297               0.7034\n",
       "16               1.0987               1.4031\n",
       "17               1.2677               0.5659\n",
       "18               1.4368               1.8389\n",
       "19               1.6058               1.2964"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std_ized = (df - df.mean()) / df.std()\n",
    "df_std_ized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "54a5420e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.0000</td>\n",
       "      <td>20.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.6058</td>\n",
       "      <td>-1.9987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.8029</td>\n",
       "      <td>-0.6743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.8029</td>\n",
       "      <td>0.6003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.6058</td>\n",
       "      <td>1.8389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "{\\centering\n",
       "\\begin{tabular}{lrr}\n",
       "\\toprule\n",
       "{} &                    x &                    y \\\\\n",
       "\\midrule\n",
       "count &              20.0000 &              20.0000 \\\\\n",
       "mean  &               0.0000 &               0.0000 \\\\\n",
       "std   &               1.0000 &               1.0000 \\\\\n",
       "min   &              -1.6058 &              -1.9987 \\\\\n",
       "25\\%   &              -0.8029 &              -0.6743 \\\\\n",
       "50\\%   &               0.0000 &               0.0444 \\\\\n",
       "75\\%   &               0.8029 &               0.6003 \\\\\n",
       "max   &               1.6058 &               1.8389 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\n",
       "\\medskip}"
      ],
      "text/plain": [
       "                         x                    y\n",
       "count              20.0000              20.0000\n",
       "mean                0.0000               0.0000\n",
       "std                 1.0000               1.0000\n",
       "min                -1.6058              -1.9987\n",
       "25%                -0.8029              -0.6743\n",
       "50%                 0.0000               0.0444\n",
       "75%                 0.8029               0.6003\n",
       "max                 1.6058               1.8389"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_std_ized.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f76285ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/latex": [
       "{\\centering\n",
       "\\begin{tabular}{lrr}\n",
       "\\toprule\n",
       "{} &                    x &                    y \\\\\n",
       "\\midrule\n",
       "mean &               0.0000 &               0.0000 \\\\\n",
       "std  &               1.0000 &               1.0000 \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\n",
       "\\medskip}"
      ],
      "text/plain": [
       "                        x                    y\n",
       "mean               0.0000               0.0000\n",
       "std                1.0000               1.0000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_std_ized.describe().loc[['mean', 'std']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e860fa",
   "metadata": {},
   "source": [
    "We can look at the original data and the standardized data on two different scales: the natural scale that `matplotlib` wants to use for the data and a simple, fixed, zoomed-out scale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "98f8cad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Standardized Data')"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(5, 5))\n",
    "\n",
    "ax[0,0].plot(df.x, df.y, '.')\n",
    "ax[0,1].plot(df_std_ized.x, df_std_ized.y, '.')\n",
    "ax[0,0].set_ylabel(\"'Natural' Scale\")\n",
    "\n",
    "ax[1,0].plot(df.x, df.y, '.')\n",
    "ax[1,1].plot(df_std_ized.x, df_std_ized.y, '.')\n",
    "\n",
    "ax[1,0].axis([-10, 50, -10, 50])\n",
    "ax[1,1].axis([-10, 50, -10, 50])\n",
    "\n",
    "ax[1,0].set_ylabel('Fixed/Shared Scale')\n",
    "ax[1,0].set_xlabel('Original Data')\n",
    "ax[1,1].set_xlabel('Standardized Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af4559b",
   "metadata": {},
   "source": [
    "After standardizing, the shape of the data stays the same.  You can clearly see this in the top row--where the data are on different scales and in different locations.  \n",
    "\n",
    "In the top row, `matplotlib` uses different scales to empasize the data's *shape*.  In the bottom row, a fixed common scale emphasize that the *location* and the *spread* of the data are different.  Standardizing shifts the data to be centered at zero and scales the data so that the resulting values have a standard deviation and variance of 1.0.\n",
    "\n",
    "We can perform standarization in `sklearn` using a special 'learner' named `StandardScaler`.  The learner figures out the mean and standard deviation from the training data and applies these values to transform the traing or test data.  The name of this in `sklearn` is *Transformer*.  `fit` works the same way as it does for the learners we've seen so far.  \n",
    "\n",
    "However, instead of `predict`, we use `transform`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b79c7adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.0526]\n",
      " [ 5.2632]\n",
      " [ 8.4211]\n",
      " [-3.4211]\n",
      " [ 9.2105]\n",
      " [-5.    ]\n",
      " [ 2.8947]\n",
      " [10.    ]\n",
      " [ 4.4737]\n",
      " [ 0.5263]]\n",
      "[[-1.0526]\n",
      " [ 2.1053]\n",
      " [-0.2632]\n",
      " [ 3.6842]\n",
      " [ 7.6316]\n",
      " [-4.2105]\n",
      " [ 1.3158]\n",
      " [-2.6316]\n",
      " [-1.8421]\n",
      " [ 6.8421]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.0037],\n",
       "       [-0.3561],\n",
       "       [-0.8418],\n",
       "       [-0.0324],\n",
       "       [ 0.777 ],\n",
       "       [-1.6512],\n",
       "       [-0.518 ],\n",
       "       [-1.3274],\n",
       "       [-1.1655],\n",
       "       [ 0.6151]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_xs, test_xs = skms.train_test_split(xs.reshape(-1, 1), test_size=.5)\n",
    "print(train_xs)\n",
    "print(test_xs)\n",
    "scaler = skpre.StandardScaler()\n",
    "scaler.fit(train_xs).transform(test_xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d77233",
   "metadata": {},
   "source": [
    "Now, we will talk about pipelines, where we can standardize and then fit in a model in one condensed package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a24f746b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.    , -4.2105, -3.4211, -2.6316, -1.8421, -1.0526, -0.2632,\n",
       "        0.5263,  1.3158,  2.1053,  2.8947,  3.6842,  4.4737,  5.2632,\n",
       "        6.0526,  6.8421,  7.6316,  8.4211,  9.2105, 10.    ])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_xs, test_xs,\n",
    " train_ys, test_ys) = skms.train_test_split(xs.reshape(-1, 1),\n",
    "                                            ys.reshape(-1, 1),\n",
    "                                            test_size=.5)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1946dc92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.5999],\n",
       "       [64.8115],\n",
       "       [58.3527],\n",
       "       [16.3705],\n",
       "       [13.1411],\n",
       "       [71.2703],\n",
       "       [45.4351],\n",
       "       [35.7469],\n",
       "       [48.6645],\n",
       "       [ 9.9117]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = skpre.StandardScaler()\n",
    "lr = linear_model.LinearRegression()\n",
    "\n",
    "std_lr_pipe = pipeline.make_pipeline(scaler, lr)\n",
    "\n",
    "std_lr_pipe.fit(train_xs, train_ys).predict(test_xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fd295e",
   "metadata": {},
   "source": [
    "The pipline acts just like any other learner we've seen: it has `fit` and `predict` methods.  We can use a pipeline as a plug-in substitute for any other learning method.  \n",
    "\n",
    "We use the *same interface* whether the learners are stand-alone components or built up from primitive components.  \n",
    "\n",
    "Even though the `StandardScaler` uses `transform` when it is applied stand-alone, the overall pipeline uses `predict` to apply the transformation.  Calling `my_pipe.predict()` will do the transformations necessary to get to the final product without having to explicity call the `transform` step.\n",
    "\n",
    "You may have noticed we are learning the parameters we use to standardize (our training mean and standard deviation).\n",
    "We do that from the *training* set.  We do not want to peek with a learning model, we also don't want to peek with our preprocessing.  \n",
    "\n",
    "Never peek at the test data unless there is (1) a formal proof that peeking won't bias or invalidate your results and (2) you understand the limits of the formal proof and when it may *not* apply, so that again, you're back in a scenario wher you shouldn't peek.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c750a",
   "metadata": {},
   "source": [
    "# 7.5 Evaluating Regressors in a More Sophisticated Way: Take Two"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee60c8",
   "metadata": {},
   "source": [
    "We not turn back to the Portuguese student data for a larger example.  We have the same data we used in Chapter 6, except we keep the target feature as a numerical value.  \n",
    "\n",
    "Therefore, we just have the numerical features from the original dataset and the`G3` column as our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "96f73444",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-161-a0fb6c0d288d>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-161-a0fb6c0d288d>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    # download zip file and un\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "student_url = ('https://archie.ics.uci.edu/' +\n",
    "               'ml/machine-learning-databases/00320/student.zip')\n",
    "def grab_student_numeric():\n",
    "    # download zip file and un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68baaf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('student-mat.csv', sep=';')\n",
    "student_df = df.drop(columns=['G1', 'G2']).select_dtypes(include=['number'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c4aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display(student_df[['absences']].describe().T)\n",
    "student_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8429058e",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_ftrs = student_df[student_df.columns[:-1]]\n",
    "student_tgt = student_df['G3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c4de52",
   "metadata": {},
   "source": [
    "## 7.5.1 Cross-Validated Results on Multiple Metrics\n",
    "\n",
    "The following uses `skms.cross_validate` to score over multiple metrics.  \n",
    "\n",
    "It is a nice convenience function that allows us to evaluate multiple metrics with one call.  It works to capture the amount of time spent to fit and predict with the given model.\n",
    "\n",
    "We will ignore those pieces and just make use of the multiple metric evaluations that it returns.\n",
    "\n",
    "Like `skms.cross_val_score`, it requires `scoreres` passed into the `scoring` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bf9ed5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaler = skpre.StandardScaler()\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "knn_3 =  neighbors.KNeighborsRegressor(n_neighbors=3)\n",
    "knn_10 = neighbors.KNeighborsRegressor(n_neighbors=10)\n",
    "\n",
    "std_lr_pipe = pipeline.make_pipeline(scaler, lr)\n",
    "std_knn3_pipe = pipeline.make_pipeline(scaler, knn_3)\n",
    "std_knn10_pipe = pipeline.make_pipeline(scaler, knn_10)\n",
    "\n",
    "# mean with/without Standardization should give some results\n",
    "regressors = {'baseline'  : dummy.DummyRegressor(strategy='mean'),\n",
    "              'std_knn3'  : std_knn3_pipe,\n",
    "              'std_knn10' : std_knn10_pipe, \n",
    "              'std_lr'    : std_lr_pipe}\n",
    "\n",
    "msrs = {'MAE'  : metrics.make_scorer(metrics.mean_absolute_error),\n",
    "        'RMSE' : metrics.make_scorer(rms_error)}\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(6, 4))\n",
    "fig.tight_layout()\n",
    "for mod_name, model in regressors.items():\n",
    "    cv_results = skms.cross_validate(model,\n",
    "                                     student_ftrs, student_tgt,\n",
    "                                     scoring = msrs, cv=10)\n",
    "    for ax, msr in zip(axes, msrs):\n",
    "        msr_results = cv_results['test_' + msr]\n",
    "        my_lbl = f'{mod_name:12s} {msr_results.mean():.3f} {msr_results.std():.2f}'\n",
    "        \n",
    "        ax.plot(msr_results, 'o--', label=my_lbl)\n",
    "        ax.set_title(msr)\n",
    "        ax.legend(bbox_to_anchor=(1, 0.5), fancybox=True, shadow=True) # uncomment for summary stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c260135a",
   "metadata": {},
   "source": [
    "3-NN is not serving us very well in this problem: the baseline method generally has less error than 3-NN.  For several folds, 10-NN and LR perform very similar and their overall performance is mostly on par with on another and slightly better than baseline.  We can tease out some of the close values--and get a more direct comparison with the baseline regressor, by looking at the ratio of $MSEs = \\frac{\\sqrt{MSE_{me}}}{\\sqrt{MSE_{baseline}}} $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d09af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1, 1, figsize=(6,3))\n",
    "baseline_results = skms.cross_val_score(regressors['baseline'],\n",
    "                                        student_ftrs, student_tgt,\n",
    "                                        scoring = msrs['RMSE'], cv=10)\n",
    "\n",
    "for mod_name, model in regressors.items():\n",
    "    if mod_name.startswith('std_'):\n",
    "        cv_results = skms.cross_val_score(model,\n",
    "                                          student_ftrs, student_tgt,\n",
    "                                          scoring = msrs['RMSE'], cv=10)\n",
    "        my_lbl= f'{mod_name:12s} {cv_results.mean():.3f} {cv_results.std():.2f}'\n",
    "        \n",
    "        ax.plot(cv_results / baseline_results, 'o--', label=my_lbl)\n",
    "ax.set_title('RMSE(model) / RMSE(baseline)\\n$<1$ is better than baseline')\n",
    "ax.legend(bbox_to_anchor=(1, 0.5), fancybox=True, shadow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0a573a",
   "metadata": {},
   "source": [
    "Here, it is clear that 3-NN is generating more error than baseline since its ratios are bigger than 1 and it is worse than the other two regressors.  We see that LR seems to be a bit of awinner on more folds, although 10-NN does eek out a few victories in folds 6-9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec04342",
   "metadata": {},
   "source": [
    "Let's see the default $R^2$ scoring for this problem, although it is easily abused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57103ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(6, 3))\n",
    "for mod_name, model in regressors.items():\n",
    "    cv_results = skms.cross_val_score(model,\n",
    "                                      student_ftrs, student_tgt,\n",
    "                                      cv=10)\n",
    "    my_lbl = f'{mod_name:12s} {cv_results.mean():.3f} {cv_results.std():.2f}'\n",
    "    \n",
    "    ax.plot(cv_results, 'o--', label=my_lbl)\n",
    "ax.set_title('$R^2$')\n",
    "ax.legend(fancybox=True, shadow=True, bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508bdd28",
   "metadata": {},
   "source": [
    "There are two interesting patterns here.  Linear regression is consistently better than *k*-NN-R.  The *order* of the winnders on each fold seems to be the same.  \n",
    "\n",
    "Why doesn't the baseline model, which has a mean predictor model, have an $R^2$ value of zero?\n",
    "\n",
    "There's going to be different values for the means of training and testing sets.  We are doing train-test splitting wrapped up in cross-validation, our training and testing means are going to be a bit off from each other, but not too much.  You'll notice that most of the $R^2$ values for the baseline mare are in the vicinity of zero.  That's the price we pay for randomness and using $R^2$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27abb857",
   "metadata": {},
   "source": [
    "# 7.5.2 Summarizing Cross-Validated Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da063d0",
   "metadata": {},
   "source": [
    "Another approach to cross-validated predictions is to view the entire cross-validation process as a single learner.  Remember, each example is in *one and only one* testing scenario in cross-validation.  Therefore, we can simply gather up all the predictions, made by a basket of learners training on different partitions of the data, and compare them with our known targets.  \n",
    "\n",
    "Applying an evaluation metric to these predictions and targets gives us a net result of a *single* value for each model and metric.  We access the predictions with `cross_val_predict.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012bc4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "msrs = {'MAE'  : metrics.mean_absolute_error,\n",
    "        'RMSE' : rms_error} # not scorer, no model\n",
    "\n",
    "results = {}\n",
    "for mod_name, model in regressors.items():\n",
    "    cv_preds = skms.cross_val_predict(model,\n",
    "                                      student_ftrs, student_tgt,\n",
    "                                      cv=10)\n",
    "    for ax, msr in zip(axes, msrs):\n",
    "        msr_results = msrs[msr](student_tgt, cv_preds)\n",
    "        results.setdefault(msr, []).append(msr_results)\n",
    "        \n",
    "df = pd.DataFrame(results, index=regressors.keys())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab055ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "msr_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e82a9",
   "metadata": {},
   "source": [
    "# 7.5.3 Residuals\n",
    "\n",
    "\n",
    "Let's look at (1) the residuals of our baseline model and (2) using the standardized, preprocessed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8578d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(10, 5),\n",
    "                         sharex=True, sharey=True)\n",
    "fig.tight_layout()\n",
    "for model_name, ax in zip(regressors, axes):\n",
    "    model = regressors[model_name]\n",
    "    preds = skms.cross_val_predict(model,\n",
    "                                   student_ftrs, student_tgt,\n",
    "                                   cv=10)\n",
    "    \n",
    "    regression_residuals(ax, preds, student_tgt)\n",
    "    ax.set_title(model_name + ' residuals')\n",
    "pd.DataFrame(student_tgt).describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d80e1a6",
   "metadata": {},
   "source": [
    "Key points:\n",
    "\n",
    "* Even though we are using the mean model as our baseline model, we have multiple means, one mean for each training-split.  Our predicted values only have a slight variation for the mean-only models(s)\n",
    "\n",
    "* The residuals for our standardize-then-fit models have some striking patterns.\n",
    "\n",
    "    1. They all show banding.  The banding is due to the integer values of the target: there are target values of 17 and 18, but not 17.5.  Therefore, there are distinct gaps.\n",
    "    2. The overall patterns seem quite similar for each nonbaseline model.\n",
    "    3. There's a whole band of 'error outliers' where all of the residuals are negative and keep decreasing with the amount of the prediction.  Negative residuals are positive errors.  It indicates that we are overpredicting.  On the right, we predict 15, and we are over by about 15, as the actual is near zero.  On the left, we predict 5 and we've over by about 5, the actual is, again, near zero.  So the *reason* we see that band is that it shows us our *maximum* error (minimum residual) at each possible predicted value.  If we predict *x* and the actual value is zero, our error is *x* (residual of -*x*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabd44c6",
   "metadata": {},
   "source": [
    "# 7.6 EOC\n",
    "\n",
    "## 7.6.1 \n",
    "\n",
    "We added (1) baseline regression models, (2) residual plots, and (3) some appropriate metrics.  We also looked at pipelines and standardization and discussed some of the difficulties of the metrics above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e54dd",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
